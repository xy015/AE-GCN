{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba2efc51-2416-4351-bb2a-ed11328340fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.11.0 and strictly below 2.14.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle as p\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import os, time, copy, math\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from random import seed, shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage.color import gray2rgb\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.myutils import *\n",
    "from utils.gcnutils import *\n",
    "\n",
    "import tf_geometric as tfg\n",
    "from tf_geometric.utils import tf_utils\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten,Reshape, Dropout, BatchNormalization, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import GlobalMaxPool2D, Concatenate\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 设置TensorFlow的日志级别为2，只显示error和warining信息\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8871127-209a-4d98-a8a1-5acdd6c96f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/VIT/\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./data/slices60/\"  # 数据路径\n",
    "model_path = \"./model/VIT/\"  # 设置模型保存目录\n",
    "for path in [model_path]:\n",
    "    print(path)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffda5212-4faa-4d88-9a4b-959a9d4238e8",
   "metadata": {},
   "source": [
    "# 1.读入GCN数据表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7721bfa1-4da7-4d61-8276-fc41d4ad152d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>lung</th>\n",
       "      <th>position</th>\n",
       "      <th>Image.type</th>\n",
       "      <th>Pathology</th>\n",
       "      <th>病理分级</th>\n",
       "      <th>Size.cm.</th>\n",
       "      <th>...</th>\n",
       "      <th>脉管瘤栓</th>\n",
       "      <th>淋巴结转移</th>\n",
       "      <th>flag_1</th>\n",
       "      <th>flag_2</th>\n",
       "      <th>flag_3</th>\n",
       "      <th>flag</th>\n",
       "      <th>Zrange</th>\n",
       "      <th>Zmed</th>\n",
       "      <th>slices</th>\n",
       "      <th>nID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>157</td>\n",
       "      <td>222</td>\n",
       "      <td>241</td>\n",
       "      <td>右肺</td>\n",
       "      <td>中叶</td>\n",
       "      <td>纯磨玻璃</td>\n",
       "      <td>MIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[241, 256]</td>\n",
       "      <td>248</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>157</td>\n",
       "      <td>222</td>\n",
       "      <td>242</td>\n",
       "      <td>右肺</td>\n",
       "      <td>中叶</td>\n",
       "      <td>纯磨玻璃</td>\n",
       "      <td>MIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[241, 256]</td>\n",
       "      <td>248</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>157</td>\n",
       "      <td>222</td>\n",
       "      <td>243</td>\n",
       "      <td>右肺</td>\n",
       "      <td>中叶</td>\n",
       "      <td>纯磨玻璃</td>\n",
       "      <td>MIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[241, 256]</td>\n",
       "      <td>248</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>157</td>\n",
       "      <td>222</td>\n",
       "      <td>244</td>\n",
       "      <td>右肺</td>\n",
       "      <td>中叶</td>\n",
       "      <td>纯磨玻璃</td>\n",
       "      <td>MIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[241, 256]</td>\n",
       "      <td>248</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>157</td>\n",
       "      <td>222</td>\n",
       "      <td>245</td>\n",
       "      <td>右肺</td>\n",
       "      <td>中叶</td>\n",
       "      <td>纯磨玻璃</td>\n",
       "      <td>MIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[241, 256]</td>\n",
       "      <td>248</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10858</th>\n",
       "      <td>635</td>\n",
       "      <td>165</td>\n",
       "      <td>156</td>\n",
       "      <td>183</td>\n",
       "      <td>右肺</td>\n",
       "      <td>中叶</td>\n",
       "      <td>部分实性</td>\n",
       "      <td>腺癌</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>无</td>\n",
       "      <td>无</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[178, 187]</td>\n",
       "      <td>182</td>\n",
       "      <td>10</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10859</th>\n",
       "      <td>635</td>\n",
       "      <td>165</td>\n",
       "      <td>156</td>\n",
       "      <td>184</td>\n",
       "      <td>右肺</td>\n",
       "      <td>中叶</td>\n",
       "      <td>部分实性</td>\n",
       "      <td>腺癌</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>无</td>\n",
       "      <td>无</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[178, 187]</td>\n",
       "      <td>182</td>\n",
       "      <td>10</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10860</th>\n",
       "      <td>635</td>\n",
       "      <td>165</td>\n",
       "      <td>156</td>\n",
       "      <td>185</td>\n",
       "      <td>右肺</td>\n",
       "      <td>中叶</td>\n",
       "      <td>部分实性</td>\n",
       "      <td>腺癌</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>无</td>\n",
       "      <td>无</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[178, 187]</td>\n",
       "      <td>182</td>\n",
       "      <td>10</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10861</th>\n",
       "      <td>635</td>\n",
       "      <td>165</td>\n",
       "      <td>156</td>\n",
       "      <td>186</td>\n",
       "      <td>右肺</td>\n",
       "      <td>中叶</td>\n",
       "      <td>部分实性</td>\n",
       "      <td>腺癌</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>无</td>\n",
       "      <td>无</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[178, 187]</td>\n",
       "      <td>182</td>\n",
       "      <td>10</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10862</th>\n",
       "      <td>635</td>\n",
       "      <td>165</td>\n",
       "      <td>156</td>\n",
       "      <td>187</td>\n",
       "      <td>右肺</td>\n",
       "      <td>中叶</td>\n",
       "      <td>部分实性</td>\n",
       "      <td>腺癌</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>无</td>\n",
       "      <td>无</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[178, 187]</td>\n",
       "      <td>182</td>\n",
       "      <td>10</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10863 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID    X    Y    Z lung position Image.type Pathology  病理分级  Size.cm.  \\\n",
       "0        7  157  222  241   右肺       中叶       纯磨玻璃       MIA   NaN       1.5   \n",
       "1        7  157  222  242   右肺       中叶       纯磨玻璃       MIA   NaN       1.5   \n",
       "2        7  157  222  243   右肺       中叶       纯磨玻璃       MIA   NaN       1.5   \n",
       "3        7  157  222  244   右肺       中叶       纯磨玻璃       MIA   NaN       1.5   \n",
       "4        7  157  222  245   右肺       中叶       纯磨玻璃       MIA   NaN       1.5   \n",
       "...    ...  ...  ...  ...  ...      ...        ...       ...   ...       ...   \n",
       "10858  635  165  156  183   右肺       中叶       部分实性        腺癌   1.0       1.2   \n",
       "10859  635  165  156  184   右肺       中叶       部分实性        腺癌   1.0       1.2   \n",
       "10860  635  165  156  185   右肺       中叶       部分实性        腺癌   1.0       1.2   \n",
       "10861  635  165  156  186   右肺       中叶       部分实性        腺癌   1.0       1.2   \n",
       "10862  635  165  156  187   右肺       中叶       部分实性        腺癌   1.0       1.2   \n",
       "\n",
       "       ...  脉管瘤栓  淋巴结转移  flag_1 flag_2 flag_3 flag      Zrange Zmed slices  \\\n",
       "0      ...   NaN    NaN       0      0      0    0  [241, 256]  248     16   \n",
       "1      ...   NaN    NaN       0      0      0    0  [241, 256]  248     16   \n",
       "2      ...   NaN    NaN       0      0      0    0  [241, 256]  248     16   \n",
       "3      ...   NaN    NaN       0      0      0    0  [241, 256]  248     16   \n",
       "4      ...   NaN    NaN       0      0      0    0  [241, 256]  248     16   \n",
       "...    ...   ...    ...     ...    ...    ...  ...         ...  ...    ...   \n",
       "10858  ...     无      无       0      0      0    0  [178, 187]  182     10   \n",
       "10859  ...     无      无       0      0      0    0  [178, 187]  182     10   \n",
       "10860  ...     无      无       0      0      0    0  [178, 187]  182     10   \n",
       "10861  ...     无      无       0      0      0    0  [178, 187]  182     10   \n",
       "10862  ...     无      无       0      0      0    0  [178, 187]  182     10   \n",
       "\n",
       "       nID  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "...    ...  \n",
       "10858  482  \n",
       "10859  482  \n",
       "10860  482  \n",
       "10861  482  \n",
       "10862  482  \n",
       "\n",
       "[10863 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读入结节信息\n",
    "dat  = pd.read_csv(\"/mnt/GCNxin/data/是否微乳头_GNN.csv\",encoding = 'utf-8')\n",
    "dat.sort_values(by=[\"nID\",\"ID\",\"Z\"], ascending=[True, True, True], inplace=True)  # 按结节nID，病人ID，Z轴升序排列\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fcb2dd-98e2-439c-b87e-9154ee5b15ff",
   "metadata": {},
   "source": [
    "# 2.划分训练集、验证集、测试集\n",
    "#### 复现VGG16+CBAM的划分情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0562830b-dcbf-482b-aa69-45fc0c5d9d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_IDs</th>\n",
       "      <th>valid_IDs</th>\n",
       "      <th>test_IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98</td>\n",
       "      <td>63.0</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>626</td>\n",
       "      <td>268.0</td>\n",
       "      <td>543.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589</td>\n",
       "      <td>380.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>454</td>\n",
       "      <td>183.0</td>\n",
       "      <td>267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>231</td>\n",
       "      <td>375.0</td>\n",
       "      <td>540.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     train_IDs  valid_IDs  test_IDs\n",
       "0           98       63.0     191.0\n",
       "1          626      268.0     543.0\n",
       "2          589      380.0     177.0\n",
       "3          454      183.0     267.0\n",
       "4          231      375.0     540.0\n",
       "..         ...        ...       ...\n",
       "250        173        NaN       NaN\n",
       "251        436        NaN       NaN\n",
       "252        595        NaN       NaN\n",
       "253        621        NaN       NaN\n",
       "254        290        NaN       NaN\n",
       "\n",
       "[255 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDs = pd.read_csv(\"/mnt/GCNxin/output.csv\", encoding = 'utf-8', low_memory=False)\n",
    "IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93c4249d-05a8-4288-9371-8af310778972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98, 626, 589, 454, 231, 230, 119, 163, 568, 398, 461, 404, 444, 84, 284, 549, 574, 627, 562, 27, 312, 85, 510, 339, 203, 414, 580, 297, 519, 498, 400, 132, 298, 350, 402, 176, 430, 317, 114, 555, 167, 250, 333, 448, 55, 458, 281, 480, 272, 26, 277, 289, 299, 417, 296, 547, 566, 603, 273, 438, 354, 346, 386, 31, 511, 429, 310, 201, 550, 325, 295, 393, 249, 142, 171, 168, 399, 150, 185, 453, 258, 44, 366, 77, 497, 136, 394, 565, 587, 321, 349, 373, 304, 33, 66, 504, 544, 396, 523, 356, 599, 293, 209, 324, 329, 248, 166, 413, 422, 487, 144, 408, 336, 83, 90, 237, 22, 484, 631, 303, 502, 241, 216, 331, 283, 145, 632, 48, 246, 431, 172, 121, 35, 623, 184, 53, 598, 614, 352, 327, 579, 462, 360, 158, 219, 467, 612, 611, 357, 501, 524, 180, 575, 178, 68, 42, 266, 337, 343, 30, 622, 456, 530, 538, 29, 397, 257, 577, 139, 76, 286, 583, 131, 236, 395, 443, 18, 122, 368, 234, 425, 529, 221, 170, 433, 164, 481, 88, 572, 213, 592, 243, 278, 37, 32, 548, 485, 308, 154, 56, 471, 188, 156, 316, 446, 340, 147, 179, 508, 223, 60, 512, 526, 159, 507, 474, 472, 496, 198, 332, 362, 244, 222, 100, 591, 20, 328, 387, 127, 437, 353, 426, 576, 563, 111, 101, 493, 194, 390, 95, 509, 545, 341, 564, 588, 64, 104, 527, 525, 482, 173, 436, 595, 621, 290]\n",
      "[191, 543, 177, 267, 540, 86, 245, 162, 54, 411, 39, 157, 363, 306, 148, 7, 202, 420, 463, 62, 255, 189, 618, 52, 214, 116, 195, 441, 224, 334, 323, 21, 556, 155, 479, 271, 112, 606, 367, 110, 215, 73, 619, 344, 251, 81, 109, 558, 464, 403, 207, 58, 91, 318, 93, 232, 407, 335, 82, 391, 57, 113, 92, 17, 450, 200, 630, 70, 455, 270, 229, 460, 153, 629, 533, 138, 274, 517, 235, 470, 322, 16, 495, 381, 585, 542]\n",
      "[63, 268, 380, 183, 375, 165, 427, 600, 206, 478, 557, 226, 253, 516, 169, 468, 359, 10, 559, 193, 490, 421, 451, 449, 442, 264, 635, 601, 376, 212, 615, 401, 374, 199, 492, 473, 419, 494, 406, 279, 19, 13, 567, 554, 620, 174, 514, 371, 388, 280, 351, 536, 115, 503, 553, 217, 47, 551, 625, 488, 432, 210, 187, 305, 535, 40, 578, 369, 466, 211, 262, 378, 476, 384, 186, 342, 282, 383, 205, 51, 345, 439, 137, 500, 140]\n",
      "[191, 543, 177, 267, 540, 86, 245, 162, 54, 411, 39, 157, 363, 306, 148, 7, 202, 420, 463, 62, 255, 189, 618, 52, 214, 116, 195, 441, 224, 334, 323, 21, 556, 155, 479, 271, 112, 606, 367, 110, 215, 73, 619, 344, 251, 81, 109, 558, 464, 403, 207, 58, 91, 318, 93, 232, 407, 335, 82, 391, 57, 113, 92, 17, 450, 200, 630, 70, 455, 270, 229, 460, 153, 629, 533, 138, 274, 517, 235, 470, 322, 16, 495, 381, 585, 542]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_IDs_list = IDs['train_IDs'].dropna().astype(int).tolist() #将病人ID删除缺失值后以整数型数据保存为列表\n",
    "test_IDs_list = IDs['test_IDs'].dropna().astype(int).tolist()\n",
    "valid_IDs_list = IDs['valid_IDs'].dropna().astype(int).tolist()\n",
    "train_IDs_listzong=train_IDs_list+valid_IDs_list # 获取训练集和验证集病人ID序列和\n",
    "print(train_IDs_list)\n",
    "print(test_IDs_list)\n",
    "print(valid_IDs_list)\n",
    "# 提取符合条件的切片，即 dat_cut DataFrame 中 ID 列属于 train_IDs_list 的切片\n",
    "#train_slices = dat_cut[dat_cut['ID'].isin(train_IDs_list)]\n",
    "#train_slices.reset_index(drop=True, inplace=True)\n",
    "type(test_IDs_list)\n",
    "len(train_IDs_listzong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38133b92-7eed-4709-9579-d1e520321d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psplitDF8(data, col_name, reset, train_IDs, test_IDs, seed=123, shuffle=False):\n",
    "    # 得到两个数据集\n",
    "    train_dat = data.loc[data[col_name].isin(train_IDs), ]  # 训练集\n",
    "    test_dat = data.loc[data[col_name].isin(test_IDs), ]  # 测试集\n",
    "    if reset == True:  # 判断是在划分训练集和测试集，还是在划分训练集和验证集\n",
    "        train_dat = train_dat.reset_index(drop=True)  # 重设索引为连续的整数，从0开始\n",
    "        test_dat = test_dat.reset_index(drop=True)\n",
    "        train_index = list(range(len(train_dat)))  # 更新 train_index，使用range函数生成从0开始的连续整数序列\n",
    "        test_index = list(range(len(test_dat)))  # 更新 test_index，使用range函数生成从0开始的连续整数序列\n",
    "    else:\n",
    "        # 提取索引，用于模型训练\n",
    "        train_index = train_dat.index.tolist()  # 训练集索引\n",
    "        test_index = test_dat.index.tolist()  # 测试集索引\n",
    "    # 返回训练集表、测试集表、训练集表索引、测试集表索引\n",
    "    return train_dat, test_dat, train_index, test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa343322-ce32-4013-940e-f786d50bdfe4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据中训练集切片数: 6578，微乳头切片占比: 38.81%，结节数: 291, 微乳头结节占比：31.2%，病人数: 255\n",
      "训练数据中验证集切片数: 2278，微乳头切片占比: 34.77%，结节数: 99, 微乳头结节占比：31.0%，病人数: 85\n",
      "测试数据中测试集切片数: 2007，微乳头切片占比: 40.01%，结节数: 93, 微乳头结节占比：28.35%，病人数: 86\n",
      "训练集: [34, 35, 36, 37, 38]\n",
      "验证集: 5\n",
      "测试集: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2278"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dat, test_dat, _, test_index = psplitDF8(dat, \"ID\",  train_IDs=train_IDs_listzong,test_IDs= test_IDs_list, reset=True)  # 按病人ID划分为训练集和测试集\n",
    "len(train_dat)\n",
    "train_datz, valid_dat, train_index, valid_index = psplitDF8(train_dat, \"ID\", train_IDs=train_IDs_list,test_IDs= valid_IDs_list,reset=False)  # 按病人ID将训练集再划分为训练集和验证集\n",
    "\n",
    "print(f\"训练数据中训练集{pcalRate(train_dat, train_index)}\")\n",
    "print(f\"训练数据中验证集{pcalRate(train_dat, valid_index)}\")\n",
    "print(f\"测试数据中测试集{pcalRate(test_dat, test_index)}\")\n",
    "print(f\"训练集: {train_index[:5]}\")\n",
    "print(f\"验证集: {valid_index[5]}\")\n",
    "print(f\"测试集: {test_index}\")\n",
    "len(train_index)\n",
    "len(valid_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd0de2c2-7944-4aed-a239-9c4e808533c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>lung</th>\n",
       "      <th>position</th>\n",
       "      <th>Image.type</th>\n",
       "      <th>Pathology</th>\n",
       "      <th>病理分级</th>\n",
       "      <th>Size.cm.</th>\n",
       "      <th>...</th>\n",
       "      <th>脉管瘤栓</th>\n",
       "      <th>淋巴结转移</th>\n",
       "      <th>flag_1</th>\n",
       "      <th>flag_2</th>\n",
       "      <th>flag_3</th>\n",
       "      <th>flag</th>\n",
       "      <th>Zrange</th>\n",
       "      <th>Zmed</th>\n",
       "      <th>slices</th>\n",
       "      <th>nID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>18</td>\n",
       "      <td>195</td>\n",
       "      <td>336</td>\n",
       "      <td>182</td>\n",
       "      <td>右肺</td>\n",
       "      <td>下叶</td>\n",
       "      <td>纯实性</td>\n",
       "      <td>腺癌</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>...</td>\n",
       "      <td>无</td>\n",
       "      <td>无</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[182, 228]</td>\n",
       "      <td>205</td>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>18</td>\n",
       "      <td>195</td>\n",
       "      <td>336</td>\n",
       "      <td>183</td>\n",
       "      <td>右肺</td>\n",
       "      <td>下叶</td>\n",
       "      <td>纯实性</td>\n",
       "      <td>腺癌</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>...</td>\n",
       "      <td>无</td>\n",
       "      <td>无</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[182, 228]</td>\n",
       "      <td>205</td>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>18</td>\n",
       "      <td>195</td>\n",
       "      <td>336</td>\n",
       "      <td>184</td>\n",
       "      <td>右肺</td>\n",
       "      <td>下叶</td>\n",
       "      <td>纯实性</td>\n",
       "      <td>腺癌</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>...</td>\n",
       "      <td>无</td>\n",
       "      <td>无</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[182, 228]</td>\n",
       "      <td>205</td>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>18</td>\n",
       "      <td>195</td>\n",
       "      <td>336</td>\n",
       "      <td>185</td>\n",
       "      <td>右肺</td>\n",
       "      <td>下叶</td>\n",
       "      <td>纯实性</td>\n",
       "      <td>腺癌</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>...</td>\n",
       "      <td>无</td>\n",
       "      <td>无</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[182, 228]</td>\n",
       "      <td>205</td>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>18</td>\n",
       "      <td>195</td>\n",
       "      <td>336</td>\n",
       "      <td>186</td>\n",
       "      <td>右肺</td>\n",
       "      <td>下叶</td>\n",
       "      <td>纯实性</td>\n",
       "      <td>腺癌</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>...</td>\n",
       "      <td>无</td>\n",
       "      <td>无</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[182, 228]</td>\n",
       "      <td>205</td>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8841</th>\n",
       "      <td>632</td>\n",
       "      <td>293</td>\n",
       "      <td>291</td>\n",
       "      <td>24</td>\n",
       "      <td>左肺</td>\n",
       "      <td>上叶</td>\n",
       "      <td>纯实性</td>\n",
       "      <td>腺癌</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>有</td>\n",
       "      <td>无</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[15, 28]</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8842</th>\n",
       "      <td>632</td>\n",
       "      <td>293</td>\n",
       "      <td>291</td>\n",
       "      <td>25</td>\n",
       "      <td>左肺</td>\n",
       "      <td>上叶</td>\n",
       "      <td>纯实性</td>\n",
       "      <td>腺癌</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>有</td>\n",
       "      <td>无</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[15, 28]</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8843</th>\n",
       "      <td>632</td>\n",
       "      <td>293</td>\n",
       "      <td>291</td>\n",
       "      <td>26</td>\n",
       "      <td>左肺</td>\n",
       "      <td>上叶</td>\n",
       "      <td>纯实性</td>\n",
       "      <td>腺癌</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>有</td>\n",
       "      <td>无</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[15, 28]</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8844</th>\n",
       "      <td>632</td>\n",
       "      <td>293</td>\n",
       "      <td>291</td>\n",
       "      <td>27</td>\n",
       "      <td>左肺</td>\n",
       "      <td>上叶</td>\n",
       "      <td>纯实性</td>\n",
       "      <td>腺癌</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>有</td>\n",
       "      <td>无</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[15, 28]</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8845</th>\n",
       "      <td>632</td>\n",
       "      <td>293</td>\n",
       "      <td>291</td>\n",
       "      <td>28</td>\n",
       "      <td>左肺</td>\n",
       "      <td>上叶</td>\n",
       "      <td>纯实性</td>\n",
       "      <td>腺癌</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>有</td>\n",
       "      <td>无</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[15, 28]</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6578 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID    X    Y    Z lung position Image.type Pathology  病理分级  Size.cm.  \\\n",
       "34     18  195  336  182   右肺       下叶        纯实性        腺癌   3.0       3.3   \n",
       "35     18  195  336  183   右肺       下叶        纯实性        腺癌   3.0       3.3   \n",
       "36     18  195  336  184   右肺       下叶        纯实性        腺癌   3.0       3.3   \n",
       "37     18  195  336  185   右肺       下叶        纯实性        腺癌   3.0       3.3   \n",
       "38     18  195  336  186   右肺       下叶        纯实性        腺癌   3.0       3.3   \n",
       "...   ...  ...  ...  ...  ...      ...        ...       ...   ...       ...   \n",
       "8841  632  293  291   24   左肺       上叶        纯实性        腺癌   3.0       1.3   \n",
       "8842  632  293  291   25   左肺       上叶        纯实性        腺癌   3.0       1.3   \n",
       "8843  632  293  291   26   左肺       上叶        纯实性        腺癌   3.0       1.3   \n",
       "8844  632  293  291   27   左肺       上叶        纯实性        腺癌   3.0       1.3   \n",
       "8845  632  293  291   28   左肺       上叶        纯实性        腺癌   3.0       1.3   \n",
       "\n",
       "      ...  脉管瘤栓  淋巴结转移  flag_1 flag_2 flag_3 flag      Zrange Zmed slices  nID  \n",
       "34    ...     无      无       1      1      1    1  [182, 228]  205     47    5  \n",
       "35    ...     无      无       1      1      1    1  [182, 228]  205     47    5  \n",
       "36    ...     无      无       1      1      1    1  [182, 228]  205     47    5  \n",
       "37    ...     无      无       1      1      1    1  [182, 228]  205     47    5  \n",
       "38    ...     无      无       1      1      1    1  [182, 228]  205     47    5  \n",
       "...   ...   ...    ...     ...    ...    ...  ...         ...  ...    ...  ...  \n",
       "8841  ...     有      无       1      1      0    1    [15, 28]   21     14  481  \n",
       "8842  ...     有      无       1      1      0    1    [15, 28]   21     14  481  \n",
       "8843  ...     有      无       1      1      0    1    [15, 28]   21     14  481  \n",
       "8844  ...     有      无       1      1      0    1    [15, 28]   21     14  481  \n",
       "8845  ...     有      无       1      1      0    1    [15, 28]   21     14  481  \n",
       "\n",
       "[6578 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cefccac6-15e8-4a13-ae09-969639dcff33",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18  20  22  26  27  29  30  31  32  33  35  37  42  44  48  53  55  56\n",
      "  60  64  66  68  76  77  83  84  85  88  90  95  98 100 101 104 111 114\n",
      " 119 121 122 127 131 132 136 139 142 144 145 147 150 154 156 158 159 163\n",
      " 164 166 167 168 170 171 172 173 176 178 179 180 184 185 188 194 198 201\n",
      " 203 209 213 216 219 221 222 223 230 231 234 236 237 241 243 244 246 248\n",
      " 249 250 257 258 266 272 273 277 278 281 283 284 286 289 290 293 295 296\n",
      " 297 298 299 303 304 308 310 312 316 317 321 324 325 327 328 329 331 332\n",
      " 333 336 337 339 340 341 343 346 349 350 352 353 354 356 357 360 362 366\n",
      " 368 373 386 387 390 393 394 395 396 397 398 399 400 402 404 408 413 414\n",
      " 417 422 425 426 429 430 431 433 436 437 438 443 444 446 448 453 454 456\n",
      " 458 461 462 467 471 472 474 480 481 482 484 485 487 493 496 497 498 501\n",
      " 502 504 507 508 509 510 511 512 519 523 524 525 526 527 529 530 538 544\n",
      " 545 547 548 549 550 555 562 563 564 565 566 568 572 574 575 576 577 579\n",
      " 580 583 587 588 589 591 592 595 598 599 603 611 612 614 621 622 623 626\n",
      " 627 631 632]\n",
      "[  7  16  17  21  39  52  54  57  58  62  70  73  81  82  86  91  92  93\n",
      " 109 110 112 113 116 138 148 153 155 157 162 177 189 191 195 200 202 207\n",
      " 214 215 224 229 232 235 245 251 255 267 270 271 274 306 318 322 323 334\n",
      " 335 344 363 367 381 391 403 407 411 420 441 450 455 460 463 464 470 479\n",
      " 495 517 533 540 542 543 556 558 585 606 618 619 629 630]\n",
      "255\n",
      "86\n",
      "85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#得到各数据集无重复的ID值\n",
    "tra_seq=train_datz[\"ID\"].unique()\n",
    "val_seq=valid_dat[\"ID\"].unique()\n",
    "tes_seq=test_dat[\"ID\"].unique()\n",
    "len(tes_seq)\n",
    "print(tra_seq)\n",
    "print(tes_seq)\n",
    "print(len(tra_seq))\n",
    "print(len(tes_seq))\n",
    "print(len(val_seq))\n",
    "tes_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31ccc42f-bc37-4e5e-a16c-d3b12e3597e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: 6578\n",
      "Valid Images: 2278\n",
      "Test Images: 2007\n"
     ]
    }
   ],
   "source": [
    "tra_image = []\n",
    "val_image = []\n",
    "tes_image = []\n",
    "\n",
    "# 获取所有结节文件路径，并按指定顺序排序\n",
    "imagePaths = glob(data_path + \"*/*flag_*.npy\")\n",
    "imagePaths.sort(key=lambda x: [int(x.split(\"nID_\")[1].split(\",\")[0]), int(x.split(\"ID_\")[1].split(\",\")[0])], reverse=False)\n",
    "\n",
    "# 将tra_seq、val_seq和tes_seq转换为set\n",
    "tra_seq_set = set(tra_seq)\n",
    "val_seq_set = set(val_seq)\n",
    "tes_seq_set = set(tes_seq)\n",
    "##按照ID值划分训练集、验证集、测试集\n",
    "for i, image_path in enumerate(imagePaths):\n",
    "    x = image_path.split(\" ID_\")[1].split(\",\")[0]\n",
    "    a = int(x)\n",
    "    if a in tra_seq_set:\n",
    "        tra_image.append(image_path)\n",
    "    elif a in val_seq_set:\n",
    "        val_image.append(image_path)\n",
    "    elif a in tes_seq_set:\n",
    "        tes_image.append(image_path)\n",
    "\n",
    "print(\"Train Images:\", len(tra_image))\n",
    "print(\"Valid Images:\", len(val_image))\n",
    "print(\"Test Images:\", len(tes_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9b1236-c8f2-4b86-acde-deeeee74abc6",
   "metadata": {},
   "source": [
    "#### 构建训练集y_train、测试集y_test和验证集y_valid的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03971090-ff8e-4afd-907f-2e153a3c2948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2278,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#构建0-1y\n",
    "y_train=[]\n",
    "y_test=[]\n",
    "y_valid=[]\n",
    "for i in range(6578):\n",
    "    file_path = trainSets[i][0]  # 获取文件路径\n",
    "    c = int(file_path.split('flag_')[1].split(\".\")[0])#提取文件路径中的标签(0或1)并将其附加到列表 y_train\n",
    "    y_train.append(c)\n",
    "    \n",
    "for i in range(2007):\n",
    "    file_path = testSets[i][0]  # 获取文件路径\n",
    "    c = int(file_path.split('flag_')[1].split(\".\")[0])\n",
    "    y_test.append(c)\n",
    "    \n",
    "for i in range(2278):\n",
    "    file_path = validSets[i][0]  # 获取文件路径\n",
    "    c = int(file_path.split('flag_')[1].split(\".\")[0])\n",
    "    y_valid.append(c)  \n",
    "\n",
    "#print(y_test)\n",
    "type(y_test)\n",
    "y_train=np.array(y_train)\n",
    "type(y_train)\n",
    "y_test=np.array(y_test)\n",
    "type(y_test)\n",
    "y_test.shape\n",
    "type(y_valid)\n",
    "y_valid=np.array(y_valid)\n",
    "y_valid.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6abdfda1-55cb-4099-b4c1-e96b00061007",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n",
    "y_train=list(y_train)\n",
    "y_train=np.array(y_train)\n",
    "y_train.resize((6578, 1))#调整y_train数组的形状为(6578, 1)\n",
    "print(y_train)\n",
    "y_test=list(y_test)\n",
    "y_test=np.array(y_test)\n",
    "y_test.resize((2007, 1))#调整y_test数组的形状为(2007, 1)\n",
    "y_valid=list(y_valid)\n",
    "y_valid=np.array(y_valid)\n",
    "y_valid.resize((2278, 1))#调整y_valid数组的形状为(2278, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68a73c13-32d4-47ae-87c6-73f715c2d94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "803\n"
     ]
    }
   ],
   "source": [
    "#计算测试集中微乳头切片的数量\n",
    "count2=0\n",
    "for i in range(2007):\n",
    "    if y_test[i]==1:\n",
    "        count2=count2+1\n",
    "print(count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d008ceb-73af-4866-b50a-ceb791df6927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792\n"
     ]
    }
   ],
   "source": [
    "#计算验证集中微乳头切片的数量\n",
    "count3=0\n",
    "for i in range(2278):\n",
    "    if y_valid[i]==1:\n",
    "        count3=count3+1\n",
    "print(count3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f6e5ddd-25c2-4a8c-9f1e-f0a99e7eb3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2553\n"
     ]
    }
   ],
   "source": [
    "#计算训练集中微乳头切片的数量\n",
    "count1=0\n",
    "for i in range(6578):\n",
    "    if y_train[i]==1:\n",
    "        count1=count1+1\n",
    "print(count1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885b95f1-fbbd-44c9-9461-d17ef644064e",
   "metadata": {},
   "source": [
    "#### 数据预处理（单通道转RGB三通道）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a94948d-811b-41d0-9a83-78edb72cfd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取单个npy文件\n",
    "def get_data_from_file(filePath):\n",
    "    img_gray = np.load(filePath)  # 读取npy，[60,60]\n",
    "    img_rgb = gray2rgb(img_gray)  # 第一种办法，灰度图转RGB，[60,60,3]\n",
    "    #img_rgb = np.repeat(img_gray[..., np.newaxis], 1, -1)  # 第二种办法，单通道复制为3通道，[60,60,3]\n",
    "    #print(tes_image[0].shape)\n",
    "    #img_rgb=tf.image.resize(img_rgb, [32,32])\n",
    "    #print(resized)\n",
    "    return img_rgb\n",
    "\n",
    "# 遍历列表，读取多个npy文件，组合成一个batch\n",
    "def combineBatch(paths):\n",
    "    batch_data = []\n",
    "    for path in paths:\n",
    "        batch_data.append(get_data_from_file(path))\n",
    "    return np.asarray(batch_data)  # [B,H,W,C]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bed846-0212-4938-b530-adcbaccbaf79",
   "metadata": {},
   "source": [
    "#### 将切片数据分batch输入模型，得到各切片的featuremap，最后可以构成特征矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ed2460a-fd69-48f6-b1cb-0a7af7b8e66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:20<00:00,  6.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6578, 60, 60, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练\n",
    "features1 = []\n",
    "batchsize = 50  # 每个batch的数据量\n",
    "N = len(tra_image)  # 样本总数\n",
    "batchs = N // batchsize  # 分多少个batch计算\n",
    "for ibatch in trange(batchs):  # 遍历每个整数batch\n",
    "    batchPaths = tra_image[ibatch * batchsize: (ibatch+1) * batchsize]  # 数据路径切片\n",
    "    batchData = combineBatch(batchPaths)  # 组合batch数据\n",
    "    features1.append(batchData)\n",
    "batchPaths = imagePaths[(ibatch+1) * batchsize: N]  # 数据路径切片\n",
    "batchData = combineBatch(batchPaths)  # 组合batch数据\n",
    "features1.append(batchData)  # 存储featuremap\n",
    "features1 = np.vstack(features1)\n",
    "\n",
    "features1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35055dba-1319-4585-9a36-658f12bf9116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:07<00:00,  6.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2278, 60, 60, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#验证\n",
    "features3 = []\n",
    "batchsize = 50  # 每个batch的数据量\n",
    "N = len(val_image)  # 样本总数\n",
    "batchs = N // batchsize  # 分多少个batch计算\n",
    "for ibatch in trange(batchs):  # 遍历每个整数batch\n",
    "    batchPaths = val_image[ibatch * batchsize: (ibatch+1) * batchsize]  # 数据路径切片\n",
    "    batchData = combineBatch(batchPaths)  # 组合batch数据\n",
    "    features3.append(batchData)\n",
    "batchPaths = imagePaths[(ibatch+1) * batchsize: N]  # 数据路径切片\n",
    "batchData = combineBatch(batchPaths)  # 组合batch数据\n",
    "features3.append(batchData)  # 存储featuremap\n",
    "features3 = np.vstack(features3)\n",
    "\n",
    "features3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e63358b4-8546-48ce-ba7e-4b0a8ae93321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:06<00:00,  7.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2007, 60, 60, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#测试\n",
    "features2 = []\n",
    "batchsize = 40  # 每个batch的数据量\n",
    "N = len(tes_image)  # 样本总数\n",
    "batchs = N // batchsize  # 分多少个batch计算\n",
    "for ibatch in trange(batchs):  # 遍历每个整数batch\n",
    "    batchPaths = tes_image[ibatch * batchsize: (ibatch+1) * batchsize]  # 数据路径切片\n",
    "    batchData = combineBatch(batchPaths)  # 组合batch数据\n",
    "    features2.append(batchData)\n",
    "batchPaths = imagePaths[(ibatch+1) * batchsize: N]  # 数据路径切片\n",
    "batchData = combineBatch(batchPaths)  # 组合batch数据\n",
    "features2.append(batchData)  # 存储featuremap\n",
    "features2 = np.vstack(features2)\n",
    "\n",
    "features2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296cb2c9-3b4f-4dfc-8381-89ef3e19524e",
   "metadata": {},
   "source": [
    "# 3.构建VIT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0791e04c-294e-4b96-825b-8f3a04366628",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1 #二分类任务，问题类别数量设置为1\n",
    "input_shape = (60, 60, 3)\n",
    "#定义训练超参数\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 50\n",
    "num_epochs = 100\n",
    "image_size = 72  # We'll resize input images to this size\n",
    "patch_size = 6  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2 #图像块总数量\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "#定义 Transformer 层的单元大小\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 8 #模型中Transformer 层的数量。\n",
    "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e187b478-93a3-4bef-b61d-bfaa5f9ea5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据增强\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.Resizing(image_size, image_size),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc8a80d8-170b-4064-8fb7-6ca67e802c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61882330-e4ed-4842-b7af-f7d8c778cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#从图像中提取patch\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'patch_size': self.patch_size}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f9335c4-ada1-4c23-9bac-8cfdad4bb237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#对图像的每个patch进行编码\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        #一个全连接层，其输出维度为projection_dim，没有指明激活函数\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        #定义一个嵌入层，这是一个可学习的层\n",
    "        #输入维度为num_patches，输出维度为projection_dim\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    " \n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "    def get_config(self):\n",
    "        config = super(PatchEncoder, self).get_config()\n",
    "        config.update({\n",
    "            'num_patches': self.num_patches,\n",
    "            'projection_dim': self.projection.units,  # 获取 Dense 层的输出维度\n",
    "        })\n",
    "        return config #返回配置信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "754688a7-e1f4-447a-ae1f-56c4ac54f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义Vision Transformer（ViT）结构\n",
    "def create_vit_classifier():\n",
    "    #input_shape = (60, 60, 3)\n",
    "    #inputs = layers.Input(shape=input_shape)\n",
    "    inputs=keras.Input(shape=(60, 60, 3))\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "    #augmented = inputs\n",
    "    #augmented = augmented_train_batches(inputs)    \n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    " \n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    " \n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    features=Reshape((1,1,1024), name='features_reshape')(features)\n",
    "    # Channel Attention\n",
    "    avgpool = GlobalAveragePooling2D(name='channel_avgpool')(features)\n",
    "    maxpool = GlobalMaxPool2D(name='channel_maxpool')(features)\n",
    "# Shared MLP\n",
    "    Dense_layer1 = Dense(1024//32,activation='relu', name='channel_fc1')\n",
    "    Dense_layer2 = Dense(1024, activation='relu', name='channel_fc2')\n",
    "    avg_out = Dense_layer2(Dense_layer1(avgpool))\n",
    "    max_out = Dense_layer2(Dense_layer1(maxpool))\n",
    "\n",
    "    channel = layers.add([avg_out, max_out])\n",
    "    channel = Activation('sigmoid', name='channel_sigmoid')(channel)\n",
    "    channel = Reshape((1,1,1024), name='channel_reshape')(channel)\n",
    "    channel_out = tf.multiply(features, channel)\n",
    "    \n",
    "# Spatial Attention\n",
    "    avgpool = tf.reduce_mean(channel_out, axis=3, keepdims=True, name='spatial_avgpool')\n",
    "    maxpool = tf.reduce_max(channel_out, axis=3, keepdims=True, name='spatial_maxpool')\n",
    "    spatial = Concatenate(axis=3)([avgpool, maxpool])\n",
    "\n",
    "    spatial = Conv2D(1, (7,7), strides=1, padding='same',name='spatial_conv2d')(spatial)\n",
    "    spatial_out = Activation('sigmoid', name='spatial_sigmoid')(spatial)\n",
    "    spatial_out=BatchNormalization()(features)\n",
    "\n",
    "    CBAM_out = tf.multiply(channel_out, spatial_out)\n",
    "    features=CBAM_out\n",
    "    \n",
    "    # Classify outputs.\n",
    "    features = keras.layers.GlobalAveragePooling2D()(features)\n",
    "    logits = layers.Dense(num_classes)(features)\n",
    "    \n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b76c9366-66fe-4440-a8be-cc3d0dd07bef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 60, 60, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "data_augmentation (Sequential)  (None, 72, 72, 3)    7           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "patches_1 (Patches)             (None, None, 108)    0           data_augmentation[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "patch_encoder (PatchEncoder)    (None, 144, 64)      16192       patches_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 144, 64)      128         patch_encoder[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 144, 64)      66368       layer_normalization[0][0]        \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 144, 64)      0           multi_head_attention[0][0]       \n",
      "                                                                 patch_encoder[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 144, 64)      128         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 144, 128)     8320        layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 144, 128)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 144, 64)      8256        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 144, 64)      0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 144, 64)      0           dropout_1[0][0]                  \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 144, 64)      128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 144, 64)      66368       layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 144, 64)      0           multi_head_attention_1[0][0]     \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 144, 64)      128         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 144, 128)     8320        layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 144, 128)     0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 144, 64)      8256        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 144, 64)      0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 144, 64)      0           dropout_3[0][0]                  \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, 144, 64)      128         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_2 (MultiHe (None, 144, 64)      66368       layer_normalization_4[0][0]      \n",
      "                                                                 layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 144, 64)      0           multi_head_attention_2[0][0]     \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 144, 64)      128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 144, 128)     8320        layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 144, 128)     0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 144, 64)      8256        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 144, 64)      0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 144, 64)      0           dropout_5[0][0]                  \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNor (None, 144, 64)      128         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_3 (MultiHe (None, 144, 64)      66368       layer_normalization_6[0][0]      \n",
      "                                                                 layer_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 144, 64)      0           multi_head_attention_3[0][0]     \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, 144, 64)      128         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 144, 128)     8320        layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 144, 128)     0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 144, 64)      8256        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 144, 64)      0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 144, 64)      0           dropout_7[0][0]                  \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_8 (LayerNor (None, 144, 64)      128         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_4 (MultiHe (None, 144, 64)      66368       layer_normalization_8[0][0]      \n",
      "                                                                 layer_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 144, 64)      0           multi_head_attention_4[0][0]     \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_9 (LayerNor (None, 144, 64)      128         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 144, 128)     8320        layer_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 144, 128)     0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 144, 64)      8256        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 144, 64)      0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 144, 64)      0           dropout_9[0][0]                  \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_10 (LayerNo (None, 144, 64)      128         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_5 (MultiHe (None, 144, 64)      66368       layer_normalization_10[0][0]     \n",
      "                                                                 layer_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 144, 64)      0           multi_head_attention_5[0][0]     \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_11 (LayerNo (None, 144, 64)      128         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 144, 128)     8320        layer_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 144, 128)     0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 144, 64)      8256        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 144, 64)      0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 144, 64)      0           dropout_11[0][0]                 \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_12 (LayerNo (None, 144, 64)      128         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_6 (MultiHe (None, 144, 64)      66368       layer_normalization_12[0][0]     \n",
      "                                                                 layer_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 144, 64)      0           multi_head_attention_6[0][0]     \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_13 (LayerNo (None, 144, 64)      128         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 144, 128)     8320        layer_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 144, 128)     0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 144, 64)      8256        dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 144, 64)      0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 144, 64)      0           dropout_13[0][0]                 \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_14 (LayerNo (None, 144, 64)      128         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_7 (MultiHe (None, 144, 64)      66368       layer_normalization_14[0][0]     \n",
      "                                                                 layer_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 144, 64)      0           multi_head_attention_7[0][0]     \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_15 (LayerNo (None, 144, 64)      128         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 144, 128)     8320        layer_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 144, 128)     0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 144, 64)      8256        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 144, 64)      0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 144, 64)      0           dropout_15[0][0]                 \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_16 (LayerNo (None, 144, 64)      128         add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 9216)         0           layer_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 9216)         0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 2048)         18876416    dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 2048)         0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1024)         2098176     dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 1024)         0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "features_reshape (Reshape)      (None, 1, 1, 1024)   0           dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "channel_avgpool (GlobalAverageP (None, 1024)         0           features_reshape[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "channel_maxpool (GlobalMaxPooli (None, 1024)         0           features_reshape[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "channel_fc1 (Dense)             (None, 32)           32800       channel_avgpool[0][0]            \n",
      "                                                                 channel_maxpool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "channel_fc2 (Dense)             (None, 1024)         33792       channel_fc1[0][0]                \n",
      "                                                                 channel_fc1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 1024)         0           channel_fc2[0][0]                \n",
      "                                                                 channel_fc2[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "channel_sigmoid (Activation)    (None, 1024)         0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "channel_reshape (Reshape)       (None, 1, 1, 1024)   0           channel_sigmoid[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 1, 1, 1024)   0           features_reshape[0][0]           \n",
      "                                                                 channel_reshape[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1, 1, 1024)   4096        features_reshape[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None, 1, 1, 1024)   0           tf.math.multiply[0][0]           \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1024)         0           tf.math.multiply_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1)            1025        global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 21,728,232\n",
      "Trainable params: 21,726,177\n",
      "Non-trainable params: 2,055\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vit_classifier = create_vit_classifier()\n",
    "vit_classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa25fa-4d70-48c0-bda3-a2c5dcf5ee9b",
   "metadata": {},
   "source": [
    "#### 模型编译与训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28c9b341-2d29-4a23-a63e-0a4d9eebf54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 ms, sys: 2.28 ms, total: 17.2 ms\n",
      "Wall time: 14 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "vit_classifier.compile(\n",
    "        optimizer=optimizer,\n",
    "        #loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        metrics=[keras.metrics.BinaryAccuracy()\n",
    "        #metrics=[\n",
    "        #    keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "            #keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "#optimizer=keras.optimizers.Adam(1e-5),  # Very low learning rate\n",
    "              #loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              #metrics=[keras.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95ffeaa2-23d2-4dae-b751-6f1002fc840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint_filepath =\"model_bak.hdf5\"\n",
    "train_start = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "checkpoint_filepath =os.path.join(model_path, f'{train_start} vit_gcn_best.h5')\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_binary_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "    )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "906f9a7a-3293-48c3-b20e-156f1dab44bb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "132/132 [==============================] - 24s 101ms/step - loss: 2.1317 - binary_accuracy: 0.6323 - val_loss: 0.6410 - val_binary_accuracy: 0.6497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.7469 - binary_accuracy: 0.6669 - val_loss: 0.6473 - val_binary_accuracy: 0.6462\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 12s 91ms/step - loss: 0.5803 - binary_accuracy: 0.7133 - val_loss: 0.6581 - val_binary_accuracy: 0.6576\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.5506 - binary_accuracy: 0.7271 - val_loss: 0.6652 - val_binary_accuracy: 0.6475\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.5261 - binary_accuracy: 0.7355 - val_loss: 0.6543 - val_binary_accuracy: 0.6510\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.4965 - binary_accuracy: 0.7448 - val_loss: 0.7160 - val_binary_accuracy: 0.6501\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.4916 - binary_accuracy: 0.7533 - val_loss: 0.6974 - val_binary_accuracy: 0.6374\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.4656 - binary_accuracy: 0.7701 - val_loss: 0.6194 - val_binary_accuracy: 0.6396\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.4507 - binary_accuracy: 0.7749 - val_loss: 0.6326 - val_binary_accuracy: 0.6725\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 12s 90ms/step - loss: 0.4355 - binary_accuracy: 0.7846 - val_loss: 0.6616 - val_binary_accuracy: 0.6980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4c8a265040>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_classifier.fit(\n",
    "        x=features1,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=10,\n",
    "        validation_data=(features3, y_valid),\n",
    "        callbacks=[checkpoint_callback],\n",
    "        #callbacks=callback\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e933f487-da0f-4b51-907b-253c430c47ff",
   "metadata": {},
   "source": [
    "#### 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c37fa1a-50ce-4e74-b332-a30453248e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.0316936 ]\n",
      " [-0.87854105]\n",
      " [-0.9556446 ]\n",
      " ...\n",
      " [-0.12032406]\n",
      " [-0.3178721 ]\n",
      " [-0.12473962]]\n"
     ]
    }
   ],
   "source": [
    "result=vit_classifier.predict(features2)#对测试集进行模型预测\n",
    "#pred = tf.argmax(result, axis=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e778163-77a4-4135-9f6d-255be470bb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.39454126358032227"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#计算阈值，将预测结果转换为0或1\n",
    "result.max()\n",
    "result.min()\n",
    "result.shape\n",
    "a=result.min()+(result.max()-result.min())/2\n",
    "result1=result.tolist() # 将预测结果转换为列表\n",
    "type(result.tolist())\n",
    "pred1={}\n",
    "for i in range(2007):\n",
    "    if result1[i]<=a:\n",
    "        pred1[i]=0\n",
    "    else:\n",
    "        pred1[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5971a62-7e36-43e4-8706-0a763d21382b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1206\n"
     ]
    }
   ],
   "source": [
    "#统计预测结果为1（微乳头）的数量\n",
    "count=0\n",
    "for i in range(2007):\n",
    "    if pred1[i]==1:\n",
    "        count=count+1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "207edec6-3666-42a3-af9a-bd6de08676fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提取预测结果\n",
    "#pred1=pred1.numpy()\n",
    "pred1 = pred1.items()\n",
    "# Convert object to a list\n",
    "pred1= list(pred1) \n",
    "# Convert list to an array\n",
    "pred1 = np.array(pred1) \n",
    "# print the numpy array\n",
    "print(type(pred1))\n",
    "#type(y_test)\n",
    "print(type(result))\n",
    "pred=pred1[:,1]\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26f6378-8490-4d07-8909-bcf363816ac1",
   "metadata": {},
   "source": [
    "# 4.模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01556a68-6dea-4972-8257-1807fed7f7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[707 497]\n",
      " [ 94 709]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC_pred</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>PPV</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ACC_argmax</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.705531</td>\n",
       "      <td>0.587209</td>\n",
       "      <td>0.882939</td>\n",
       "      <td>0.587894</td>\n",
       "      <td>0.882647</td>\n",
       "      <td>0.705824</td>\n",
       "      <td>0.705531</td>\n",
       "      <td>0.818815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACC_pred  Specificity  Sensitivity       PPV       NPV  F1-Score  \\\n",
       "0  0.705531     0.587209     0.882939  0.587894  0.882647  0.705824   \n",
       "\n",
       "   ACC_argmax       AUC  \n",
       "0    0.705531  0.818815  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#切片层面\n",
    "labels_value = np.array([0, 1])\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred, labels=labels_value).ravel() ##ravel数组维度拉成一维数组\n",
    "    # Accuracy\n",
    "acc1 = accuracy_score(y_test, pred)\n",
    "#     print(\"Accuracy:{:.4f}\".format(acc1))\n",
    "    # 特异性：TN / N\n",
    "specificity = tn / (tn+fp)\n",
    "    # 敏感度：TP / P\n",
    "sensitivity= tp/(tp+fn)\n",
    "    # Positive predictive value PPV = TP / (TP + FP)\n",
    "ppv = tp / (tp+fp)\n",
    "    # Negative predictive value NPV = TN / (TN + FN)\n",
    "npv = tn / (tn+fn)\n",
    "    # F1-score\n",
    "f1 = f1_score(y_test, pred) ##结果是类别1的score\n",
    "acc2 = accuracy_score(y_test, pred)\n",
    "    # ROC曲线\n",
    "fpr, tpr, thresholds = roc_curve(y_test, result[:])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "    # 最佳阈值\n",
    "i = np.arange(len(tpr)) # index for df\n",
    "roc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),'tpr' : pd.Series(tpr, index = i), '1-fpr' : pd.Series(1-fpr, index = i), 'tf' : pd.Series(tpr - (1-fpr), index = i), 'thresholds' : pd.Series(thresholds, index = i)})\n",
    "bestThresh = roc.iloc[(roc.tf-0).abs().argsort()[:1]] ##argsort数组中的元素从小到大排序后的索引数组值\n",
    "title = 'Confusion matrix, without normalization'\n",
    "    # Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "    # Only use the labels that appear in the data\n",
    "classes = labels_value[unique_labels(y_test, pred)]\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "#     fig, ax = plt.subplots()\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "ax = fig.add_subplot(121)\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "ax.set(xticks=np.arange(cm.shape[1]),\n",
    "        yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "        xticklabels=classes, yticklabels=classes,\n",
    "        title=title,\n",
    "        ylabel='True label',\n",
    "        xlabel='Predicted label')\n",
    "\n",
    "ax.set_ylim(len(classes)-0.5, -0.5)\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=0, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")  \n",
    "    # Loop over data dimensions and create text annotations.\n",
    "fmt = 'd' \n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], fmt),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    # 绘制ROC曲线\n",
    "ax = fig.add_subplot(122)\n",
    "ax.plot(fpr, tpr, label='ROC')\n",
    "ax.set_xlabel('FPR')\n",
    "ax.set_ylabel('TPR')\n",
    "    \n",
    "    # 整合评估指标\n",
    "metrics_s = pd.DataFrame({\"ACC_pred\": [acc1], \"Specificity\": [specificity], \"Sensitivity\": [sensitivity],\n",
    "                            \"PPV\": [ppv], \"NPV\": [npv], \"F1-Score\": [f1], \"ACC_argmax\": [acc2], \"AUC\": [roc_auc]})\n",
    "    \n",
    "fig.tight_layout()\n",
    "metrics_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "352e3d6f-2364-4381-b7e6-37d53e14eba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算结节层面的预测结果\n",
    "pthresh=0.5\n",
    "if test_index is None:\n",
    "    noduleData = test_dat.loc[:, [\"nID\", \"ID\", \"flag\"]].copy()  # copy测试集原数据\n",
    "else:\n",
    "    noduleData = test_dat.loc[test_index, [\"nID\", \"ID\", \"flag\"]].copy()  # 复制测试集指定索引的数据\n",
    "noduleData[\"y_pred\"] = pred\n",
    "noduleData[\"0_value\"] = result\n",
    "noduleData = noduleData.groupby(\"nID\").mean()  # 平均法\n",
    "noduleData[[\"ID\",\"flag\"]] = noduleData[[\"ID\", \"flag\"]].astype(int)  # 保持数据类型\n",
    "noduleData[\"voting_pred\"] = noduleData[\"y_pred\"].apply(lambda x: 1 if x > pthresh else 0)  # 投票法得到预测标签，90%阈值\n",
    "#compreEval(noduleData[\"flag\"], noduleData[\"voting_pred\"], np.asarray(noduleData[\"0_value\"]), classes=labels_value, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d9f2481-e05b-43e3-a175-ed61f5206a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[45 22]\n",
      " [ 3 23]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC_pred</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>PPV</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ACC_argmax</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.647887</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.818599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACC_pred  Specificity  Sensitivity       PPV     NPV  F1-Score  ACC_argmax  \\\n",
       "0  0.731183     0.671642     0.884615  0.511111  0.9375  0.647887    0.731183   \n",
       "\n",
       "        AUC  \n",
       "0  0.818599  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 结节层面\n",
    "tn, fp, fn, tp = confusion_matrix(noduleData[\"flag\"], noduleData[\"voting_pred\"], labels=labels_value).ravel() ##ravel数组维度拉成一维数组\n",
    "    # Accuracy\n",
    "acc1 = accuracy_score(noduleData[\"flag\"], noduleData[\"voting_pred\"])\n",
    "#     print(\"Accuracy:{:.4f}\".format(acc1))\n",
    "    # 特异性：TN / N\n",
    "specificity = tn / (tn+fp)\n",
    "    # 敏感度：TP / P\n",
    "sensitivity= tp/(tp+fn)\n",
    "    # Positive predictive value PPV = TP / (TP + FP)\n",
    "ppv = tp / (tp+fp)\n",
    "    # Negative predictive value NPV = TN / (TN + FN)\n",
    "npv = tn / (tn+fn)\n",
    "    # F1-score\n",
    "f1 = f1_score(noduleData[\"flag\"], noduleData[\"voting_pred\"]) ##结果是类别1的score\n",
    "acc2 = accuracy_score(noduleData[\"flag\"], noduleData[\"voting_pred\"])\n",
    "    # ROC曲线\n",
    "fpr, tpr, thresholds = roc_curve(noduleData[\"flag\"], np.asarray(noduleData[\"0_value\"]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "    # 最佳阈值\n",
    "i = np.arange(len(tpr)) # index for df\n",
    "roc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),'tpr' : pd.Series(tpr, index = i), '1-fpr' : pd.Series(1-fpr, index = i), 'tf' : pd.Series(tpr - (1-fpr), index = i), 'thresholds' : pd.Series(thresholds, index = i)})\n",
    "bestThresh = roc.iloc[(roc.tf-0).abs().argsort()[:1]] ##argsort数组中的元素从小到大排序后的索引数组值\n",
    "title = 'Confusion matrix, without normalization'\n",
    "    # Compute confusion matrix\n",
    "cm = confusion_matrix(noduleData[\"flag\"], noduleData[\"voting_pred\"])\n",
    "    # Only use the labels that appear in the data\n",
    "classes = labels_value[unique_labels(noduleData[\"flag\"], noduleData[\"voting_pred\"])]\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "#     fig, ax = plt.subplots()\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "ax = fig.add_subplot(121)\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "ax.set(xticks=np.arange(cm.shape[1]),\n",
    "        yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "        xticklabels=classes, yticklabels=classes,\n",
    "        title=title,\n",
    "        ylabel='True label',\n",
    "        xlabel='Predicted label')\n",
    "ax.set_ylim(len(classes)-0.5, -0.5)\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=0, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")  \n",
    "    # Loop over data dimensions and create text annotations.\n",
    "fmt = 'd' \n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], fmt),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    # 绘制ROC曲线\n",
    "ax = fig.add_subplot(122)\n",
    "ax.plot(fpr, tpr, label='ROC')\n",
    "ax.set_xlabel('FPR')\n",
    "ax.set_ylabel('TPR')\n",
    "    # 整合评估指标\n",
    "metrics_n = pd.DataFrame({\"ACC_pred\": [acc1], \"Specificity\": [specificity], \"Sensitivity\": [sensitivity],\n",
    "                            \"PPV\": [ppv], \"NPV\": [npv], \"F1-Score\": [f1], \"ACC_argmax\": [acc2], \"AUC\": [roc_auc]})\n",
    "fig.tight_layout()\n",
    "metrics_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2538d406-5225-400f-a436-bac77091533c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC_pred</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>PPV</th>\n",
       "      <th>NPV</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ACC_argmax</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>切片级</th>\n",
       "      <td>0.449427</td>\n",
       "      <td>0.109635</td>\n",
       "      <td>0.958904</td>\n",
       "      <td>0.418024</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.582231</td>\n",
       "      <td>0.449427</td>\n",
       "      <td>0.780864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>结节级</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ACC_pred  Specificity  Sensitivity       PPV       NPV  F1-Score  \\\n",
       "切片级  0.449427     0.109635     0.958904  0.418024  0.800000  0.582231   \n",
       "结节级  0.333333     0.104478     0.923077  0.285714  0.777778  0.436364   \n",
       "\n",
       "     ACC_argmax       AUC  \n",
       "切片级    0.449427  0.780864  \n",
       "结节级    0.333333  0.769231  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metrics = pd.concat([metrics_s, metrics_n])\n",
    "metrics.index = [\"切片级\",\"结节级\"]\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a3e394c4-23f7-4c37-a2e4-977f2b2bb3b7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                           Output Shape               Param #       Connected to                            \n",
      "========================================================================================================================\n",
      "input_1 (InputLayer)                   [(None, 60, 60, 3)]        0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "data_augmentation (Sequential)         (None, 72, 72, 3)          7             input_1[0][0]                           \n",
      "________________________________________________________________________________________________________________________\n",
      "patches (Patches)                      (None, None, 108)          0             data_augmentation[0][0]                 \n",
      "________________________________________________________________________________________________________________________\n",
      "patch_encoder (PatchEncoder)           (None, 144, 64)            16192         patches[0][0]                           \n",
      "________________________________________________________________________________________________________________________\n",
      "layer_normalization (LayerNormalizatio (None, 144, 64)            128           patch_encoder[0][0]                     \n",
      "________________________________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHeadAttenti (None, 144, 64)            66368         layer_normalization[0][0]               \n",
      "                                                                                layer_normalization[0][0]               \n",
      "________________________________________________________________________________________________________________________\n",
      "add (Add)                              (None, 144, 64)            0             multi_head_attention[0][0]              \n",
      "                                                                                patch_encoder[0][0]                     \n",
      "________________________________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNormalizat (None, 144, 64)            128           add[0][0]                               \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_1 (Dense)                        (None, 144, 128)           8320          layer_normalization_1[0][0]             \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout (Dropout)                      (None, 144, 128)           0             dense_1[0][0]                           \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_2 (Dense)                        (None, 144, 64)            8256          dropout[0][0]                           \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                    (None, 144, 64)            0             dense_2[0][0]                           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_1 (Add)                            (None, 144, 64)            0             dropout_1[0][0]                         \n",
      "                                                                                add[0][0]                               \n",
      "________________________________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNormalizat (None, 144, 64)            128           add_1[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHeadAtten (None, 144, 64)            66368         layer_normalization_2[0][0]             \n",
      "                                                                                layer_normalization_2[0][0]             \n",
      "________________________________________________________________________________________________________________________\n",
      "add_2 (Add)                            (None, 144, 64)            0             multi_head_attention_1[0][0]            \n",
      "                                                                                add_1[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNormalizat (None, 144, 64)            128           add_2[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_3 (Dense)                        (None, 144, 128)           8320          layer_normalization_3[0][0]             \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)                    (None, 144, 128)           0             dense_3[0][0]                           \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_4 (Dense)                        (None, 144, 64)            8256          dropout_2[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)                    (None, 144, 64)            0             dense_4[0][0]                           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_3 (Add)                            (None, 144, 64)            0             dropout_3[0][0]                         \n",
      "                                                                                add_2[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNormalizat (None, 144, 64)            128           add_3[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "multi_head_attention_2 (MultiHeadAtten (None, 144, 64)            66368         layer_normalization_4[0][0]             \n",
      "                                                                                layer_normalization_4[0][0]             \n",
      "________________________________________________________________________________________________________________________\n",
      "add_4 (Add)                            (None, 144, 64)            0             multi_head_attention_2[0][0]            \n",
      "                                                                                add_3[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNormalizat (None, 144, 64)            128           add_4[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_5 (Dense)                        (None, 144, 128)           8320          layer_normalization_5[0][0]             \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)                    (None, 144, 128)           0             dense_5[0][0]                           \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_6 (Dense)                        (None, 144, 64)            8256          dropout_4[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)                    (None, 144, 64)            0             dense_6[0][0]                           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_5 (Add)                            (None, 144, 64)            0             dropout_5[0][0]                         \n",
      "                                                                                add_4[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNormalizat (None, 144, 64)            128           add_5[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "multi_head_attention_3 (MultiHeadAtten (None, 144, 64)            66368         layer_normalization_6[0][0]             \n",
      "                                                                                layer_normalization_6[0][0]             \n",
      "________________________________________________________________________________________________________________________\n",
      "add_6 (Add)                            (None, 144, 64)            0             multi_head_attention_3[0][0]            \n",
      "                                                                                add_5[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNormalizat (None, 144, 64)            128           add_6[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_7 (Dense)                        (None, 144, 128)           8320          layer_normalization_7[0][0]             \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)                    (None, 144, 128)           0             dense_7[0][0]                           \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_8 (Dense)                        (None, 144, 64)            8256          dropout_6[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)                    (None, 144, 64)            0             dense_8[0][0]                           \n",
      "________________________________________________________________________________________________________________________\n",
      "add_7 (Add)                            (None, 144, 64)            0             dropout_7[0][0]                         \n",
      "                                                                                add_6[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "layer_normalization_8 (LayerNormalizat (None, 144, 64)            128           add_7[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "multi_head_attention_4 (MultiHeadAtten (None, 144, 64)            66368         layer_normalization_8[0][0]             \n",
      "                                                                                layer_normalization_8[0][0]             \n",
      "________________________________________________________________________________________________________________________\n",
      "add_8 (Add)                            (None, 144, 64)            0             multi_head_attention_4[0][0]            \n",
      "                                                                                add_7[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "layer_normalization_9 (LayerNormalizat (None, 144, 64)            128           add_8[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_9 (Dense)                        (None, 144, 128)           8320          layer_normalization_9[0][0]             \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)                    (None, 144, 128)           0             dense_9[0][0]                           \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_10 (Dense)                       (None, 144, 64)            8256          dropout_8[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)                    (None, 144, 64)            0             dense_10[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "add_9 (Add)                            (None, 144, 64)            0             dropout_9[0][0]                         \n",
      "                                                                                add_8[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "layer_normalization_10 (LayerNormaliza (None, 144, 64)            128           add_9[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "multi_head_attention_5 (MultiHeadAtten (None, 144, 64)            66368         layer_normalization_10[0][0]            \n",
      "                                                                                layer_normalization_10[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "add_10 (Add)                           (None, 144, 64)            0             multi_head_attention_5[0][0]            \n",
      "                                                                                add_9[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "layer_normalization_11 (LayerNormaliza (None, 144, 64)            128           add_10[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_11 (Dense)                       (None, 144, 128)           8320          layer_normalization_11[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)                   (None, 144, 128)           0             dense_11[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_12 (Dense)                       (None, 144, 64)            8256          dropout_10[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)                   (None, 144, 64)            0             dense_12[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "add_11 (Add)                           (None, 144, 64)            0             dropout_11[0][0]                        \n",
      "                                                                                add_10[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "layer_normalization_12 (LayerNormaliza (None, 144, 64)            128           add_11[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "multi_head_attention_6 (MultiHeadAtten (None, 144, 64)            66368         layer_normalization_12[0][0]            \n",
      "                                                                                layer_normalization_12[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "add_12 (Add)                           (None, 144, 64)            0             multi_head_attention_6[0][0]            \n",
      "                                                                                add_11[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "layer_normalization_13 (LayerNormaliza (None, 144, 64)            128           add_12[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_13 (Dense)                       (None, 144, 128)           8320          layer_normalization_13[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)                   (None, 144, 128)           0             dense_13[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_14 (Dense)                       (None, 144, 64)            8256          dropout_12[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)                   (None, 144, 64)            0             dense_14[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "add_13 (Add)                           (None, 144, 64)            0             dropout_13[0][0]                        \n",
      "                                                                                add_12[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "layer_normalization_14 (LayerNormaliza (None, 144, 64)            128           add_13[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "multi_head_attention_7 (MultiHeadAtten (None, 144, 64)            66368         layer_normalization_14[0][0]            \n",
      "                                                                                layer_normalization_14[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "add_14 (Add)                           (None, 144, 64)            0             multi_head_attention_7[0][0]            \n",
      "                                                                                add_13[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "layer_normalization_15 (LayerNormaliza (None, 144, 64)            128           add_14[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_15 (Dense)                       (None, 144, 128)           8320          layer_normalization_15[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)                   (None, 144, 128)           0             dense_15[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_16 (Dense)                       (None, 144, 64)            8256          dropout_14[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)                   (None, 144, 64)            0             dense_16[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "add_15 (Add)                           (None, 144, 64)            0             dropout_15[0][0]                        \n",
      "                                                                                add_14[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "layer_normalization_16 (LayerNormaliza (None, 144, 64)            128           add_15[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "flatten (Flatten)                      (None, 9216)               0             layer_normalization_16[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)                   (None, 9216)               0             flatten[0][0]                           \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_17 (Dense)                       (None, 2048)               18876416      dropout_16[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)                   (None, 2048)               0             dense_17[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "dense_18 (Dense)                       (None, 1024)               2098176       dropout_17[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)                   (None, 1024)               0             dense_18[0][0]                          \n",
      "________________________________________________________________________________________________________________________\n",
      "features_reshape (Reshape)             (None, 1, 1, 1024)         0             dropout_18[0][0]                        \n",
      "________________________________________________________________________________________________________________________\n",
      "channel_avgpool (GlobalAveragePooling2 (None, 1024)               0             features_reshape[0][0]                  \n",
      "________________________________________________________________________________________________________________________\n",
      "channel_maxpool (GlobalMaxPooling2D)   (None, 1024)               0             features_reshape[0][0]                  \n",
      "________________________________________________________________________________________________________________________\n",
      "channel_fc1 (Dense)                    (None, 32)                 32800         channel_avgpool[0][0]                   \n",
      "                                                                                channel_maxpool[0][0]                   \n",
      "________________________________________________________________________________________________________________________\n",
      "channel_fc2 (Dense)                    (None, 1024)               33792         channel_fc1[0][0]                       \n",
      "                                                                                channel_fc1[1][0]                       \n",
      "________________________________________________________________________________________________________________________\n",
      "add_16 (Add)                           (None, 1024)               0             channel_fc2[0][0]                       \n",
      "                                                                                channel_fc2[1][0]                       \n",
      "________________________________________________________________________________________________________________________\n",
      "channel_sigmoid (Activation)           (None, 1024)               0             add_16[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "channel_reshape (Reshape)              (None, 1, 1, 1024)         0             channel_sigmoid[0][0]                   \n",
      "________________________________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)          (None, 1, 1, 1024)         0             features_reshape[0][0]                  \n",
      "                                                                                channel_reshape[0][0]                   \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization (BatchNormalizatio (None, 1, 1, 1024)         4096          features_reshape[0][0]                  \n",
      "________________________________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda)        (None, 1, 1, 1024)         0             tf.math.multiply[0][0]                  \n",
      "                                                                                batch_normalization[0][0]               \n",
      "________________________________________________________________________________________________________________________\n",
      "global_average_pooling2d (GlobalAverag (None, 1024)               0             tf.math.multiply_1[0][0]                \n",
      "========================================================================================================================\n",
      "Total params: 21,727,207\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,727,207\n",
      "________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model=vit_classifier\n",
    "featModel = Model(inputs=base_model.input, outputs=[base_model.layers[-2].output])\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False  # 设置参数不可训练\n",
    "featModel.summary(line_length=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "88e34b2b-3e6a-46d8-a564-c7fae6a99add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [01:03<00:00,  3.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10863, 1024)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = []  # 存储每个batch得到的featuremap\n",
    "batchsize = 50  # 每个batch的数据量\n",
    "N = len(imagePaths)  # 样本总数\n",
    "batchs = N // batchsize  # 分多少个batch计算\n",
    "for ibatch in trange(batchs):  # 遍历每个整数batch\n",
    "    batchPaths = imagePaths[ibatch * batchsize: (ibatch+1) * batchsize]  # 数据路径切片\n",
    "    batchData = combineBatch(batchPaths)  # 组合batch数据\n",
    "    batchfeatures = featModel.predict(batchData)  # 计算featuremap\n",
    "    features.append(batchfeatures)  # 存储featuremap\n",
    "# 计算不足整个batch的末尾数据\n",
    "batchPaths = imagePaths[(ibatch+1) * batchsize: N]  # 数据路径切片\n",
    "batchData = combineBatch(batchPaths)  # 组合batch数据\n",
    "batchfeatures = featModel.predict(batchData)  # 计算featuremap\n",
    "features.append(batchfeatures)  # 存储featuremap\n",
    "features = np.vstack(features)  # list转array，按第一维度堆叠list中的每个array\n",
    "featuremap = pd.DataFrame(features)  # array转DataFrame\n",
    "featuremap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce92a8f0-275b-426c-b9f1-d8edb89f76a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuremap.to_csv('/mnt/GCNxin/data/08病人是否微乳头featuremap_vit.csv', index = False, mode=\"w+\")#实际为CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1bd969b7-3d8b-4176-a769-c8cb20543645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10863, 1055)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>lung</th>\n",
       "      <th>position</th>\n",
       "      <th>Image.type</th>\n",
       "      <th>Pathology</th>\n",
       "      <th>病理分级</th>\n",
       "      <th>Size.cm.</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>157</td>\n",
       "      <td>222</td>\n",
       "      <td>241</td>\n",
       "      <td>右肺</td>\n",
       "      <td>中叶</td>\n",
       "      <td>纯磨玻璃</td>\n",
       "      <td>MIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851848</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>1.057025</td>\n",
       "      <td>0.003410</td>\n",
       "      <td>0.005253</td>\n",
       "      <td>-0.035086</td>\n",
       "      <td>0.216173</td>\n",
       "      <td>0.270910</td>\n",
       "      <td>0.163386</td>\n",
       "      <td>0.001619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>157</td>\n",
       "      <td>222</td>\n",
       "      <td>242</td>\n",
       "      <td>右肺</td>\n",
       "      <td>中叶</td>\n",
       "      <td>纯磨玻璃</td>\n",
       "      <td>MIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.013894</td>\n",
       "      <td>0.009787</td>\n",
       "      <td>1.014317</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>-0.026511</td>\n",
       "      <td>0.167128</td>\n",
       "      <td>0.163792</td>\n",
       "      <td>0.092711</td>\n",
       "      <td>0.000814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>157</td>\n",
       "      <td>222</td>\n",
       "      <td>243</td>\n",
       "      <td>右肺</td>\n",
       "      <td>中叶</td>\n",
       "      <td>纯磨玻璃</td>\n",
       "      <td>MIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844078</td>\n",
       "      <td>0.009889</td>\n",
       "      <td>1.019978</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.006118</td>\n",
       "      <td>-0.022410</td>\n",
       "      <td>0.107627</td>\n",
       "      <td>0.173076</td>\n",
       "      <td>0.020644</td>\n",
       "      <td>0.002769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>157</td>\n",
       "      <td>222</td>\n",
       "      <td>244</td>\n",
       "      <td>右肺</td>\n",
       "      <td>中叶</td>\n",
       "      <td>纯磨玻璃</td>\n",
       "      <td>MIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096690</td>\n",
       "      <td>-0.003053</td>\n",
       "      <td>-0.003817</td>\n",
       "      <td>0.005227</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>-0.003545</td>\n",
       "      <td>-0.020241</td>\n",
       "      <td>-0.005630</td>\n",
       "      <td>0.004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>157</td>\n",
       "      <td>222</td>\n",
       "      <td>245</td>\n",
       "      <td>右肺</td>\n",
       "      <td>中叶</td>\n",
       "      <td>纯磨玻璃</td>\n",
       "      <td>MIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513214</td>\n",
       "      <td>0.009893</td>\n",
       "      <td>0.889097</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>0.006127</td>\n",
       "      <td>-0.031775</td>\n",
       "      <td>0.058087</td>\n",
       "      <td>0.243031</td>\n",
       "      <td>0.128964</td>\n",
       "      <td>0.001180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10858</th>\n",
       "      <td>635</td>\n",
       "      <td>165</td>\n",
       "      <td>156</td>\n",
       "      <td>183</td>\n",
       "      <td>右肺</td>\n",
       "      <td>中叶</td>\n",
       "      <td>部分实性</td>\n",
       "      <td>腺癌</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570624</td>\n",
       "      <td>-0.002545</td>\n",
       "      <td>0.925489</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>0.008786</td>\n",
       "      <td>-0.011475</td>\n",
       "      <td>0.346705</td>\n",
       "      <td>-0.001749</td>\n",
       "      <td>0.003019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10859</th>\n",
       "      <td>635</td>\n",
       "      <td>165</td>\n",
       "      <td>156</td>\n",
       "      <td>184</td>\n",
       "      <td>右肺</td>\n",
       "      <td>中叶</td>\n",
       "      <td>部分实性</td>\n",
       "      <td>腺癌</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274087</td>\n",
       "      <td>-0.002747</td>\n",
       "      <td>0.531562</td>\n",
       "      <td>0.006457</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>0.007125</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.289975</td>\n",
       "      <td>-0.001729</td>\n",
       "      <td>-0.001491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10860</th>\n",
       "      <td>635</td>\n",
       "      <td>165</td>\n",
       "      <td>156</td>\n",
       "      <td>185</td>\n",
       "      <td>右肺</td>\n",
       "      <td>中叶</td>\n",
       "      <td>部分实性</td>\n",
       "      <td>腺癌</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.599354</td>\n",
       "      <td>0.006824</td>\n",
       "      <td>0.716534</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.005755</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>-0.006325</td>\n",
       "      <td>0.331472</td>\n",
       "      <td>-0.000995</td>\n",
       "      <td>0.006407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10861</th>\n",
       "      <td>635</td>\n",
       "      <td>165</td>\n",
       "      <td>156</td>\n",
       "      <td>186</td>\n",
       "      <td>右肺</td>\n",
       "      <td>中叶</td>\n",
       "      <td>部分实性</td>\n",
       "      <td>腺癌</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.595857</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>1.030891</td>\n",
       "      <td>0.003943</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>-0.012378</td>\n",
       "      <td>0.408305</td>\n",
       "      <td>-0.004224</td>\n",
       "      <td>0.003111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10862</th>\n",
       "      <td>635</td>\n",
       "      <td>165</td>\n",
       "      <td>156</td>\n",
       "      <td>187</td>\n",
       "      <td>右肺</td>\n",
       "      <td>中叶</td>\n",
       "      <td>部分实性</td>\n",
       "      <td>腺癌</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482365</td>\n",
       "      <td>0.008087</td>\n",
       "      <td>1.697576</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.276273</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>0.004383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10863 rows × 1055 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID    X    Y    Z lung position Image.type Pathology  病理分级  Size.cm.  \\\n",
       "0        7  157  222  241   右肺       中叶       纯磨玻璃       MIA   NaN       1.5   \n",
       "1        7  157  222  242   右肺       中叶       纯磨玻璃       MIA   NaN       1.5   \n",
       "2        7  157  222  243   右肺       中叶       纯磨玻璃       MIA   NaN       1.5   \n",
       "3        7  157  222  244   右肺       中叶       纯磨玻璃       MIA   NaN       1.5   \n",
       "4        7  157  222  245   右肺       中叶       纯磨玻璃       MIA   NaN       1.5   \n",
       "...    ...  ...  ...  ...  ...      ...        ...       ...   ...       ...   \n",
       "10858  635  165  156  183   右肺       中叶       部分实性        腺癌   1.0       1.2   \n",
       "10859  635  165  156  184   右肺       中叶       部分实性        腺癌   1.0       1.2   \n",
       "10860  635  165  156  185   右肺       中叶       部分实性        腺癌   1.0       1.2   \n",
       "10861  635  165  156  186   右肺       中叶       部分实性        腺癌   1.0       1.2   \n",
       "10862  635  165  156  187   右肺       中叶       部分实性        腺癌   1.0       1.2   \n",
       "\n",
       "       ...      1014      1015      1016      1017      1018      1019  \\\n",
       "0      ...  0.851848  0.009095  1.057025  0.003410  0.005253 -0.035086   \n",
       "1      ...  1.013894  0.009787  1.014317  0.006329  0.004104 -0.026511   \n",
       "2      ...  0.844078  0.009889  1.019978  0.002926  0.006118 -0.022410   \n",
       "3      ...  0.096690 -0.003053 -0.003817  0.005227  0.000527  0.010541   \n",
       "4      ...  0.513214  0.009893  0.889097  0.005528  0.006127 -0.031775   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "10858  ...  0.570624 -0.002545  0.925489  0.002478  0.004319  0.008786   \n",
       "10859  ...  0.274087 -0.002747  0.531562  0.006457  0.005021  0.007125   \n",
       "10860  ...  0.599354  0.006824  0.716534  0.000752  0.005755  0.002561   \n",
       "10861  ...  0.595857  0.002475  1.030891  0.003943  0.005675  0.000832   \n",
       "10862  ...  0.482365  0.008087  1.697576  0.002922  0.004600  0.001063   \n",
       "\n",
       "           1020      1021      1022      1023  \n",
       "0      0.216173  0.270910  0.163386  0.001619  \n",
       "1      0.167128  0.163792  0.092711  0.000814  \n",
       "2      0.107627  0.173076  0.020644  0.002769  \n",
       "3     -0.003545 -0.020241 -0.005630  0.004572  \n",
       "4      0.058087  0.243031  0.128964  0.001180  \n",
       "...         ...       ...       ...       ...  \n",
       "10858 -0.011475  0.346705 -0.001749  0.003019  \n",
       "10859  0.008660  0.289975 -0.001729 -0.001491  \n",
       "10860 -0.006325  0.331472 -0.000995  0.006407  \n",
       "10861 -0.012378  0.408305 -0.004224  0.003111  \n",
       "10862  0.004131  0.276273 -0.001124  0.004383  \n",
       "\n",
       "[10863 rows x 1055 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datGCN = pd.concat([dat, featuremap], axis=1)  # 按行合并原数据表和featuremap\n",
    "print(datGCN.shape)\n",
    "# 保存整理好的GCN数据表\n",
    "# datGCN.to_csv('csv/是否微乳头_feat_top.csv', index = False, mode=\"w+\")\n",
    "#datGCN.to_csv('csv/是否微乳头_feat_ft2.csv', index = False, mode=\"w+\")\n",
    "# datGCN.to_csv('csv/是否微乳头_feat_top+ft.csv', index = False, mode=\"w+\")\n",
    "#datGCN.to_csv('/mnt/GCNxin/data/08病人是否微乳头_VGG16_cbam4.csv', index = False, mode=\"w+\")\n",
    "#datGCN.to_csv('/mnt/GCNxin/data/08病人是否微乳头_VGG16_cbam2_non_fin08.csv', index = False, mode=\"w+\")\n",
    "#datGCN.to_csv('/mnt/GCNxin/data/08病人是否微乳头_VGG16_cbam2_fin08.csv', index = False, mode=\"w+\")\n",
    "#datGCN.to_csv('/mnt/GCNxin/data/08病人是否微乳头_VGG16_non_fin08.csv', index = False, mode=\"w+\")\n",
    "#datGCN.to_csv('/mnt/GCNxin/data/08病人是否微乳头_VGG16_CA2non_fin08.csv', index = False, mode=\"w+\")\n",
    "#datGCN.to_csv('/mnt/GCNxin/data/08病人是否微乳头_VGG16_SA2_non_fin08.csv', index = False, mode=\"w+\")\n",
    "#datGCN.to_csv('/mnt/GCNxin/data/08病人是否微乳头_VGG16_non_fin08旧对比.csv', index = False, mode=\"w+\")\n",
    "#datGCN.to_csv('/mnt/GCNxin/data/08病人是否微乳头_VGG16_non_fin08_无false.csv', index = False, mode=\"w+\")\n",
    "#微调\n",
    "datGCN.to_csv('/mnt/GCNxin/data/08病人是否微乳头_vit.csv', index = False, mode=\"w+\")#实际为CA\n",
    "datGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd40948-bae5-4e97-aafa-c842cb1090df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
