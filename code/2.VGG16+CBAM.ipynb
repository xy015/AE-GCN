{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efdbeab2-94ba-4a53-925d-c8b233cf5f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/miniconda3/envs/myconda/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import os, time, copy\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from random import seed, shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.color import gray2rgb\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.myutils import *\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 设置TensorFlow的日志级别为2，只显示error和warining信息\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.get_logger().setLevel('ERROR') #删除多余的日志\n",
    "\n",
    "import  tensorflow as tf\n",
    "from    tensorflow import keras\n",
    "from    tensorflow.keras import layers, models, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten,Reshape, Dropout, BatchNormalization, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import GlobalMaxPool2D, Concatenate\n",
    "from keras.optimizers import adam_v2\n",
    "import os, time, copy\n",
    "from glob import glob\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.layers import Multiply\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras.regularizers import l2,l1\n",
    "\n",
    "import csv\n",
    "from itertools import zip_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c61292d2-a22a-4642-9f53-f750549e022d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/VGG16/\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./data/slices60/\"  # 数据路径\n",
    "model_path = \"./model/VGG16/\"  # 设置模型保存目录\n",
    "# 创建模型目录\n",
    "for path in [model_path]:\n",
    "    print(path)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fdc069-0298-4ada-8574-b5015a86733b",
   "metadata": {},
   "source": [
    "# 1.数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5c095f-ba48-4bb1-a78b-8a6a7fea3eef",
   "metadata": {},
   "source": [
    "#### 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19425a33-099f-4fa2-8ba9-469e7351cb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/slices60/pos/nID_473, ID_622, X_133, Y_259, Z_189(186-211), diam_17, flag_1.npy'\n",
      " './data/slices60/pos/nID_418, ID_548, X_115, Y_286, Z_276(259-342), diam_46, flag_1.npy'\n",
      " './data/slices60/pos/nID_256, ID_353, X_112, Y_271, Z_235(228-248), diam_15, flag_1.npy'\n",
      " './data/slices60/pos/nID_256, ID_353, X_112, Y_271, Z_245(228-248), diam_15, flag_1.npy'\n",
      " './data/slices60/pos/nID_173, ID_243, X_419, Y_413, Z_264(226-268), diam_37, flag_1.npy']\n",
      "共有10863个npy文件\n",
      "标签类别: ['0' '1']\n",
      "[1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# 数据\n",
    "imagePaths = glob(data_path + \"*/*flag_*.npy\")  # 获取两个目录下的所有结节文件\n",
    "imagePaths = np.asarray(imagePaths)  # 转numpy\n",
    "print(imagePaths[:5])\n",
    "print(f\"共有{len(imagePaths)}个npy文件\")\n",
    "# 标签\n",
    "labels = [x.split(\"flag_\")[1].split(\".npy\")[0] for x in imagePaths]  # 提取各文件对应的标签(文件名中 \"flag_\"之后、\".npy\"之前的部分)\n",
    "# print(labels[:5])\n",
    "le = LabelEncoder()  # 标签编码器\n",
    "labels = le.fit_transform(labels)  # 处理标签，标签转数字\n",
    "print(f\"标签类别: {le.classes_}\")\n",
    "print(labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50c06c06-178a-4ef4-ac89-645501548bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('./data/slices60/pos/nID_473, ID_622, X_133, Y_259, Z_189(186-211), diam_17, flag_1.npy', 1), ('./data/slices60/pos/nID_418, ID_548, X_115, Y_286, Z_276(259-342), diam_46, flag_1.npy', 1), ('./data/slices60/pos/nID_256, ID_353, X_112, Y_271, Z_235(228-248), diam_15, flag_1.npy', 1), ('./data/slices60/pos/nID_256, ID_353, X_112, Y_271, Z_245(228-248), diam_15, flag_1.npy', 1), ('./data/slices60/pos/nID_173, ID_243, X_419, Y_413, Z_264(226-268), diam_37, flag_1.npy', 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'622'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打乱顺序\n",
    "seed(11)  # 设置random包的随机数种子\n",
    "imageSets = list(zip(imagePaths, labels))  # 配对magePaths和labels中的元素\n",
    "shuffle(imageSets)  #打乱元素顺序\n",
    "print(imageSets[:5])\n",
    "type(imageSets)\n",
    "imageSets[0][0].split(\" ID_\")[1].split(\",\")[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5ee3b1-2a55-453a-ba18-a0c85067ce0d",
   "metadata": {},
   "source": [
    "#### 对病人按6：2：2划分训练集、验证集、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfd51abf-e0e7-40b2-b76d-662c879c2924",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(imageSets)):  # 遍历每张切片提取病人ID、结节nID、结节类型标签flag\n",
    "    image_path, label = imageSets[i]\n",
    "    ID = int(image_path.split(\" ID_\")[1].split(\",\")[0])\n",
    "    nID = int(image_path.split(\"ID_\")[1].split(\",\")[0])\n",
    "    flag=int(image_path.split(\"flag_\")[1].split(\".npy\")[0])\n",
    "    imageSets[i] = (image_path, label, ID,nID,flag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03d9a041-1283-42a4-a02b-3f8256da33d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(imageSets, columns=['image_path', 'label', 'ID','nID','flag']) # 构建新数据框df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a546b780-ad9d-4454-af46-291b131c3052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['./data/slices60/pos/nID_473, ID_622, X_133, Y_259, Z_189(186-211), diam_17, flag_1.npy',\n",
       "  1,\n",
       "  622,\n",
       "  473,\n",
       "  1],\n",
       " ['./data/slices60/pos/nID_418, ID_548, X_115, Y_286, Z_276(259-342), diam_46, flag_1.npy',\n",
       "  1,\n",
       "  548,\n",
       "  418,\n",
       "  1],\n",
       " ['./data/slices60/pos/nID_256, ID_353, X_112, Y_271, Z_235(228-248), diam_15, flag_1.npy',\n",
       "  1,\n",
       "  353,\n",
       "  256,\n",
       "  1],\n",
       " ['./data/slices60/pos/nID_256, ID_353, X_112, Y_271, Z_245(228-248), diam_15, flag_1.npy',\n",
       "  1,\n",
       "  353,\n",
       "  256,\n",
       "  1],\n",
       " ['./data/slices60/pos/nID_173, ID_243, X_419, Y_413, Z_264(226-268), diam_37, flag_1.npy',\n",
       "  1,\n",
       "  243,\n",
       "  173,\n",
       "  1]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDs = df[\"ID\"].unique().tolist()  # 提取所有病人的ID\n",
    "len(IDs)\n",
    "data_list = df.values.tolist()  # df转化为二维列表\n",
    "data_list[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a03f7d4-e596-4d63-aef0-535a9ae5e1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按病人划分训练集和测试集\n",
    "def psplitDFbr(data, col_name, reset, test_size=0.2, seed=12, shuffle=True):\n",
    "    # 全部病人ID列表\n",
    "    IDs = data[col_name].unique().tolist()\n",
    "    # 病人ID列表划分为训练集和测试集\n",
    "    train_IDs, test_IDs = train_test_split(IDs, test_size=test_size, random_state=seed, shuffle=shuffle)\n",
    "    # 得到两个数据集\n",
    "    train_dat = data.loc[data[col_name].isin(train_IDs), ]  # 训练集\n",
    "    test_dat = data.loc[data[col_name].isin(test_IDs),]  # 测试集\n",
    "    if reset==True:  # 判断是在划分训练集和测试集，还是在划分训练集和验证集\n",
    "        train_dat = train_dat.reset_index(drop=True)  # 训练集\n",
    "        test_dat = test_dat.reset_index(drop=True)  # 测试集\n",
    "    # 提取索引，用于模型训练\n",
    "    train_index = train_dat.index.tolist()  # 训练集索引\n",
    "    test_index = test_dat.index.tolist()  # 测试集索引\n",
    "    # 返回训练集表、测试集表、训练集表索引、测试集表索引\n",
    "    return train_dat, test_dat, train_index, test_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40a99d42-6f81-4e25-be42-749919b4c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按病人计算各数据子集中0-1分类占比，观察样本平衡性\n",
    "def pcalRatebr(data, index):\n",
    "    # 是否通过索引进行筛选\n",
    "    if index is None:\n",
    "        n = data.shape[0]  # 如果没有提供索引，使用整个数据集的行数作为样本量\n",
    "    else:\n",
    "        n = len(index)  # 如果提供了索引，使用索引的长度作为样本量\n",
    "        data = data.loc[index, ]   # 根据索引筛选数据\n",
    "    \n",
    "    nn = len(data[\"nID\"].unique()) # 结节数量\n",
    "    pp=  len(data[\"ID\"].unique())  #病人数量\n",
    "    rate1 = round(data[\"flag\"].sum() / n * 100, 2)  # 计算数据子集中微乳头切片占比\n",
    "    rate2 = round(data.groupby(\"ID\")[\"flag\"].mean().mean() * 100, 2)  # 计算数据子集中微乳头结节占比\n",
    "    return f\"切片数: {n}，微乳头切片占比: {rate1}%，结节数: {nn}, 微乳头结节占比：{rate2}%，病人数: {pp}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0b51b24-1284-42e2-998b-be828ba2ca59",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "训练数据中训练集切片数: 6578，微乳头切片占比: 38.81%，结节数: 291, 微乳头结节占比：31.2%，病人数: 255\n",
      "训练数据中验证集切片数: 2278，微乳头切片占比: 34.77%，结节数: 99, 微乳头结节占比：31.0%，病人数: 85\n",
      "测试数据中测试集切片数: 2007，微乳头切片占比: 40.01%，结节数: 93, 微乳头结节占比：28.35%，病人数: 86\n"
     ]
    }
   ],
   "source": [
    "train_data, test_dat, _, test_index = psplitDFbr(df, \"ID\", test_size=0.2, reset=True)  # 按病人ID划分为训练集和测试集\n",
    "train_dat, valid_dat, train_index, valid_index = psplitDFbr(train_data, \"ID\", test_size=0.25, reset=False)  # 按病人ID将训练集再划分为训练集和验证集\n",
    "print(len(train_dat[\"ID\"].unique().tolist()))\n",
    "len(train_dat)\n",
    "print(f\"训练数据中训练集{pcalRatebr(train_dat, train_index)}\")\n",
    "print(f\"训练数据中验证集{pcalRatebr(valid_dat, valid_index)}\")\n",
    "print(f\"测试数据中测试集{pcalRatebr(test_dat, test_index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4959df1c-33cb-4803-b00f-627cb8ce0973",
   "metadata": {},
   "source": [
    "#### 记录数据集按病人的划分情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900cc795-4201-4e0e-b07e-6c335cb75063",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list = list(zip_longest(train_IDs,valid_IDs,test_IDs)) #合并三列ID成一个元组的列表，并用默认值填充，确保所有元组长度相同\n",
    "merged_list_name=['train_IDs','valid_IDs','test_IDs']\n",
    "data_dict_list = [dict(zip(merged_list_name, row)) for row in merged_list] #创建一个包含字典的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71f955a-aa6e-48a5-81c0-58d57961c818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将包含训练集、验证集和测试集病人ID的数据字典列表写入到名为'output.csv'的CSV文件中\n",
    "output_file = 'output.csv' \n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['train_IDs','valid_IDs','test_IDs']  # 列名\n",
    "    csv_writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    # 写入列名\n",
    "    csv_writer.writeheader()\n",
    "    # 写入数据\n",
    "    csv_writer.writerows(data_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50e9e1a1-56e4-42b4-bb33-2a7375d8d0b2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 数据提取为列表形式\n",
    "# train_dat.values.tolist() #训练集数据转化为列表\n",
    "# 从训练集中提取除了前两列（image_path和label）之外的所有列的数据，将其转换为列表\n",
    "trainSets=train_dat.drop(columns=df.columns[2:]).values.tolist()\n",
    "# 将训练集的每一行数据转换为元组，并存储在trainSets列表中\n",
    "trainSets = [tuple(data) for data in trainSets]\n",
    "testSets=test_dat.drop(columns=df.columns[2:]).values.tolist()\n",
    "testSets = [tuple(data) for data in testSets]\n",
    "validSets=valid_dat.drop(columns=df.columns[2:]).values.tolist()\n",
    "validSets = [tuple(data) for data in validSets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9058a0c-2271-417b-9bd6-90d7b1171899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据中的每一行数据转换为元组\n",
    "for i in range(len(trainSets)):\n",
    "    trainSets[i] = tuple(trainSets[i])  \n",
    "type(trainSets)\n",
    "for i in range(len(testSets)):\n",
    "    testSets[i] = tuple(testSets[i]) \n",
    "for i in range(len(validSets)):\n",
    "    validSets[i] = tuple(validSets[i]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b371c4d7-94e2-4a9d-a73a-59d84a7530cc",
   "metadata": {},
   "source": [
    "#### 数据生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7019106-7915-4de3-9b9d-80b26faebaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置参数\n",
    "trainbatchsize = 60  # 训练集batch\n",
    "valbatchsize = 40  # 测试集batch\n",
    "epochs = 50  # 训练epoch\n",
    "\n",
    "# 数据生成器\n",
    "train_generator = data_generator(trainset, batch_size=trainbatchsize, n_labels=1, labels=None, shuffle_index_list=True)\n",
    "val_generator = data_generator(validSets, batch_size=valbatchsize, n_labels=1, labels=None, shuffle_index_list=True)\n",
    "\n",
    "# 计算训练和验证的步数，在训练的时候需要这两个参数\n",
    "train_steps = get_number_of_steps(len(trainset), trainbatchsize)\n",
    "val_steps = get_number_of_steps(len(validSets), valbatchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2164e4b3-2306-4b8b-8393-fa10ca547a90",
   "metadata": {},
   "source": [
    "# 2.特征提取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f491314e-059d-4610-9b9a-b0781a2db1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 记录训练开始时间，同时作为保存模型文件名的前缀\n",
    "train_start = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "# 初始学习率为0.001，如果20个epoch后精度没有提升，学习率降低0.5；存外样本精度最高的模型\n",
    "# 构建模型文件名，包括训练开始时间（train_start），模型类型（VGG16_cbam2fin08_best.h5）\n",
    "model_file = os.path.join(model_path, f'{train_start} VGG16_cbam2fin08_best.h5')\n",
    "# 构建日志文件名，包括训练开始时间（train_start）和模型类型（VGG16_cbam08fin_metric.csv）\n",
    "logging_file = os.path.join(model_path, f\"{train_start} VGG16_cbam08fin_metric.csv\")\n",
    "# 获取回调函数，用于在训练时进行学习率衰减、保存最佳模型、记录日志等\n",
    "callback = get_callbacks(model_file, initial_learning_rate=0.001, learning_rate_drop=0.5, learning_rate_epochs=None,\n",
    "                  learning_rate_patience=20, logging_file=logging_file, verbosity=1,\n",
    "                  early_stopping_patience=10,tensorboard_callback = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff15b1d8-8cf8-47a4-86b6-55528d188bf3",
   "metadata": {},
   "source": [
    "#### 迁移学习VGG16模型，在第二个模块后加入CBAM注意力机制（消融实验所采用的backbone附在该代码的最后）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15790a33-4a99-480d-81ae-29e01bbc9854",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 60, 60, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 60, 60, 64)   1792        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 60, 60, 64)   36928       block1_conv1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 30, 30, 64)   0           block1_conv2[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 30, 30, 128)  73856       block1_pool[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 30, 30, 128)  147584      block2_conv1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "channel_avgpool (GlobalAverageP (None, 128)          0           block2_conv2[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "channel_maxpool (GlobalMaxPooli (None, 128)          0           block2_conv2[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "channel_fc1 (Dense)             (None, 16)           2064        channel_avgpool[0][0]            \n",
      "                                                                 channel_maxpool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "channel_fc2 (Dense)             (None, 128)          2176        channel_fc1[0][0]                \n",
      "                                                                 channel_fc1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 128)          0           channel_fc2[0][0]                \n",
      "                                                                 channel_fc2[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "channel_sigmoid (Activation)    (None, 128)          0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "channel_reshape (Reshape)       (None, 1, 1, 128)    0           channel_sigmoid[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "adjust_channel_dim (Conv2D)     (None, 1, 1, 128)    16512       channel_reshape[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul (TensorFlowOpLa [(None, 30, 30, 128) 0           block2_conv2[2][0]               \n",
      "                                                                 adjust_channel_dim[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_spatial_avgpool (Te [(None, 30, 30, 1)]  0           tf_op_layer_Mul[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_spatial_maxpool (Te [(None, 30, 30, 1)]  0           tf_op_layer_Mul[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 30, 30, 2)    0           tf_op_layer_spatial_avgpool[0][0]\n",
      "                                                                 tf_op_layer_spatial_maxpool[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "spatial_conv2d (Conv2D)         (None, 30, 30, 1)    99          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_sigmoid (Activation)    (None, 30, 30, 1)    0           spatial_conv2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_1 (TensorFlowOp [(None, 30, 30, 128) 0           tf_op_layer_Mul[0][0]            \n",
      "                                                                 spatial_sigmoid[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           multiple             295168      tf_op_layer_Mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           multiple             590080      block3_conv1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           multiple             590080      block3_conv2[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      multiple             0           block3_conv3[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           multiple             1180160     block3_pool[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           multiple             2359808     block4_conv1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           multiple             2359808     block4_conv2[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      multiple             0           block4_conv3[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           multiple             2359808     block4_pool[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           multiple             2359808     block5_conv1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           multiple             2359808     block5_conv2[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      multiple             0           block5_conv3[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           block5_pool[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            513         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,736,052\n",
      "Trainable params: 21,364\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  VGG16+CBAM(消融实验部分仅需要把该模块backbone替换掉即可)\n",
    "# 定义CBAM模块\n",
    "def cbam_module(x):\n",
    "    # 全局平均池化和全局最大池化\n",
    "    avgpool = GlobalAveragePooling2D(name='channel_avgpool')(x)\n",
    "    maxpool = GlobalMaxPool2D(name='channel_maxpool')(x)\n",
    "    # Shared MLP\n",
    "    Dense_layer1 = Dense(128//8,activation='relu', name='channel_fc1')\n",
    "    Dense_layer2 = Dense(128, activation='relu', name='channel_fc2')\n",
    "    avg_out = Dense_layer2(Dense_layer1(avgpool))\n",
    "    max_out = Dense_layer2(Dense_layer1(maxpool))\n",
    "\n",
    "    ## Channel Attention\n",
    "    channel = layers.add([avg_out, max_out])\n",
    "    channel = Activation('sigmoid', name='channel_sigmoid')(channel)\n",
    "    channel = Reshape((1, 1, 128), name='channel_reshape')(channel)\n",
    "    channel = Conv2D(128, (1, 1), strides=(1, 1), padding='same', name='adjust_channel_dim')(channel)\n",
    "    channel_out = tf.multiply(x, channel)\n",
    "    \n",
    "    # Spatial Attention\n",
    "    avgpool = tf.reduce_mean(channel_out, axis=3, keepdims=True, name='spatial_avgpool')\n",
    "    maxpool = tf.reduce_max(channel_out, axis=3, keepdims=True, name='spatial_maxpool')\n",
    "    spatial = Concatenate(axis=3)([avgpool, maxpool])\n",
    "\n",
    "    spatial = Conv2D(1, (7,7), strides=1, padding='same',name='spatial_conv2d')(spatial)\n",
    "    spatial_out = Activation('sigmoid', name='spatial_sigmoid')(spatial)\n",
    "    #spatial_out=BatchNormalization(x)\n",
    "\n",
    "    #CBAM输出\n",
    "    CBAM_out = tf.multiply(channel_out, spatial_out)\n",
    "    x=CBAM_out\n",
    "    return x\n",
    "# 实例化一个具有预训练权重的基础模型\n",
    "base_model = VGG16(weights=\"imagenet\", input_shape=(60,60,3), include_top=False)\n",
    "# 冻结该基础模型，参数不可变\n",
    "base_model.trainable = False\n",
    "# 根据基础模型创建一个新模型\n",
    "inputs = keras.Input(shape=(60, 60, 3))# 输入\n",
    "x = base_model(inputs, training=False)\n",
    "# 获取VGG16模型的前2个blocks\n",
    "blocks_1_2 = base_model.layers[1:6]\n",
    "blocks_3_5=base_model.layers[7:19]\n",
    "# 创建新的VGG16模型，并在第2个block后插入CBAM模块\n",
    "x = inputs\n",
    "for layer in blocks_1_2:\n",
    "    x = layer(x)\n",
    "    if layer.name == 'block2_conv2':\n",
    "        x = cbam_module(x)\n",
    "# 第3-5个block仍为原迁移学习模型\n",
    "for layer in blocks_3_5:\n",
    "    x = layer(x)\n",
    "# 增加新层\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "#创建一个Dropout层\n",
    "x=layers.Dropout(0.5)(x)\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "outputs = keras.layers.Dense(1,kernel_regularizer=l2(0.01),activity_regularizer=l1(0.02))(x)\n",
    "print(outputs.shape)\n",
    "# 创建新模型\n",
    "model_cbam = keras.Model(inputs, outputs)\n",
    "model_cbam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f38477e-84f1-4766-b654-fbad96432fe2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "144/144 [==============================] - ETA: 0s - batch: 71.5000 - size: 59.6181 - loss: 0.6680 - binary_accuracy: 0.6260"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
      "/root/miniconda3/envs/myconda/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 55s 322ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.6680 - binary_accuracy: 0.6260 - val_loss: 0.6407 - val_binary_accuracy: 0.6941 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "144/144 [==============================] - 38s 261ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.5964 - binary_accuracy: 0.6683 - val_loss: 0.5539 - val_binary_accuracy: 0.6791 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "144/144 [==============================] - 40s 277ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.5717 - binary_accuracy: 0.6990 - val_loss: 0.5428 - val_binary_accuracy: 0.7155 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "144/144 [==============================] - 39s 273ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.5637 - binary_accuracy: 0.7005 - val_loss: 0.5359 - val_binary_accuracy: 0.7424 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "144/144 [==============================] - 38s 261ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.5515 - binary_accuracy: 0.7117 - val_loss: 0.5288 - val_binary_accuracy: 0.7304 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "144/144 [==============================] - 38s 261ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.5453 - binary_accuracy: 0.7173 - val_loss: 0.5248 - val_binary_accuracy: 0.7265 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "144/144 [==============================] - 38s 263ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.5386 - binary_accuracy: 0.7213 - val_loss: 0.5182 - val_binary_accuracy: 0.7369 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "144/144 [==============================] - 40s 275ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.5397 - binary_accuracy: 0.7180 - val_loss: 0.5238 - val_binary_accuracy: 0.7439 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "144/144 [==============================] - 40s 275ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.5307 - binary_accuracy: 0.7303 - val_loss: 0.4945 - val_binary_accuracy: 0.7469 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "144/144 [==============================] - 39s 273ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.5258 - binary_accuracy: 0.7326 - val_loss: 0.4908 - val_binary_accuracy: 0.7549 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "144/144 [==============================] - 40s 277ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.5229 - binary_accuracy: 0.7401 - val_loss: 0.5201 - val_binary_accuracy: 0.7578 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "144/144 [==============================] - 39s 274ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.5147 - binary_accuracy: 0.7442 - val_loss: 0.4951 - val_binary_accuracy: 0.7713 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "144/144 [==============================] - 39s 275ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.5131 - binary_accuracy: 0.7508 - val_loss: 0.5173 - val_binary_accuracy: 0.7778 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "144/144 [==============================] - 39s 273ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.5072 - binary_accuracy: 0.7501 - val_loss: 0.4719 - val_binary_accuracy: 0.7877 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "144/144 [==============================] - 38s 261ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.5009 - binary_accuracy: 0.7535 - val_loss: 0.5010 - val_binary_accuracy: 0.7872 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "144/144 [==============================] - 40s 276ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4982 - binary_accuracy: 0.7592 - val_loss: 0.4789 - val_binary_accuracy: 0.7987 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "144/144 [==============================] - 39s 273ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4896 - binary_accuracy: 0.7674 - val_loss: 0.4819 - val_binary_accuracy: 0.8077 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "144/144 [==============================] - 38s 262ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4855 - binary_accuracy: 0.7683 - val_loss: 0.4927 - val_binary_accuracy: 0.7977 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "144/144 [==============================] - 39s 275ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4837 - binary_accuracy: 0.7715 - val_loss: 0.4811 - val_binary_accuracy: 0.8246 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "144/144 [==============================] - 40s 275ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4779 - binary_accuracy: 0.7736 - val_loss: 0.4688 - val_binary_accuracy: 0.8276 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "144/144 [==============================] - 39s 273ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4645 - binary_accuracy: 0.7831 - val_loss: 0.4723 - val_binary_accuracy: 0.8296 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "144/144 [==============================] - 37s 261ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4673 - binary_accuracy: 0.7847 - val_loss: 0.4521 - val_binary_accuracy: 0.8276 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "144/144 [==============================] - 39s 273ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4626 - binary_accuracy: 0.7852 - val_loss: 0.4420 - val_binary_accuracy: 0.8301 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "144/144 [==============================] - 39s 275ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4559 - binary_accuracy: 0.7909 - val_loss: 0.4257 - val_binary_accuracy: 0.8470 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "144/144 [==============================] - 39s 274ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4531 - binary_accuracy: 0.7925 - val_loss: 0.4380 - val_binary_accuracy: 0.8530 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "144/144 [==============================] - 38s 261ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4470 - binary_accuracy: 0.7937 - val_loss: 0.4380 - val_binary_accuracy: 0.8515 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "144/144 [==============================] - 39s 274ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4443 - binary_accuracy: 0.7999 - val_loss: 0.4271 - val_binary_accuracy: 0.8545 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "144/144 [==============================] - 38s 261ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4356 - binary_accuracy: 0.8023 - val_loss: 0.4366 - val_binary_accuracy: 0.8545 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "144/144 [==============================] - 38s 261ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4349 - binary_accuracy: 0.8077 - val_loss: 0.4483 - val_binary_accuracy: 0.8540 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "144/144 [==============================] - 39s 268ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4329 - binary_accuracy: 0.8077 - val_loss: 0.4147 - val_binary_accuracy: 0.8670 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "144/144 [==============================] - 38s 262ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4224 - binary_accuracy: 0.8139 - val_loss: 0.4131 - val_binary_accuracy: 0.8435 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "144/144 [==============================] - 39s 269ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4197 - binary_accuracy: 0.8191 - val_loss: 0.4030 - val_binary_accuracy: 0.8729 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "144/144 [==============================] - 38s 261ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4108 - binary_accuracy: 0.8246 - val_loss: 0.3933 - val_binary_accuracy: 0.8695 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "144/144 [==============================] - 38s 261ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4097 - binary_accuracy: 0.8218 - val_loss: 0.4159 - val_binary_accuracy: 0.8625 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "144/144 [==============================] - 38s 261ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4111 - binary_accuracy: 0.8221 - val_loss: 0.3897 - val_binary_accuracy: 0.8714 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "144/144 [==============================] - 39s 274ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4012 - binary_accuracy: 0.8325 - val_loss: 0.3971 - val_binary_accuracy: 0.8789 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "144/144 [==============================] - 39s 273ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4036 - binary_accuracy: 0.8310 - val_loss: 0.4200 - val_binary_accuracy: 0.8799 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "144/144 [==============================] - 39s 274ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.4019 - binary_accuracy: 0.8304 - val_loss: 0.3695 - val_binary_accuracy: 0.8809 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "144/144 [==============================] - 38s 262ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.3914 - binary_accuracy: 0.8342 - val_loss: 0.3681 - val_binary_accuracy: 0.8789 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "144/144 [==============================] - 39s 273ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.3875 - binary_accuracy: 0.8387 - val_loss: 0.3910 - val_binary_accuracy: 0.8869 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "144/144 [==============================] - 38s 261ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.3841 - binary_accuracy: 0.8419 - val_loss: 0.3618 - val_binary_accuracy: 0.8794 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "144/144 [==============================] - 38s 261ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.3806 - binary_accuracy: 0.8434 - val_loss: 0.3602 - val_binary_accuracy: 0.8769 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "144/144 [==============================] - 37s 261ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.3782 - binary_accuracy: 0.8472 - val_loss: 0.3717 - val_binary_accuracy: 0.8724 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "144/144 [==============================] - 40s 275ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.3709 - binary_accuracy: 0.8515 - val_loss: 0.3523 - val_binary_accuracy: 0.9043 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "144/144 [==============================] - 38s 261ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.3674 - binary_accuracy: 0.8540 - val_loss: 0.3503 - val_binary_accuracy: 0.8864 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "144/144 [==============================] - 38s 261ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.3676 - binary_accuracy: 0.8567 - val_loss: 0.3520 - val_binary_accuracy: 0.9023 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "144/144 [==============================] - 38s 261ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.3628 - binary_accuracy: 0.8573 - val_loss: 0.3558 - val_binary_accuracy: 0.9018 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "144/144 [==============================] - 37s 261ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.3549 - binary_accuracy: 0.8609 - val_loss: 0.3473 - val_binary_accuracy: 0.8979 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "144/144 [==============================] - 38s 261ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.3606 - binary_accuracy: 0.8610 - val_loss: 0.3440 - val_binary_accuracy: 0.8919 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "144/144 [==============================] - 39s 273ms/step - batch: 71.5000 - size: 59.6181 - loss: 0.3541 - binary_accuracy: 0.8620 - val_loss: 0.3480 - val_binary_accuracy: 0.9058 - lr: 0.0010\n",
      "CPU times: user 11min 38s, sys: 12min 39s, total: 24min 17s\n",
      "Wall time: 32min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0893eb6d60>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#测量代码执行时间\n",
    "%%time\n",
    "# 设置模型 模型编译\n",
    "model_cbam.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[keras.metrics.BinaryAccuracy()])\n",
    "# 训练模型\n",
    "model_cbam.fit(train_generator, steps_per_epoch=train_steps, epochs=50, callbacks=callback, \n",
    "          validation_data=val_generator, validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64098649-a6df-439c-8641-487c9a0e4f58",
   "metadata": {},
   "source": [
    "# 消融实验的backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d0b589-49ee-4f6b-800b-303bcedddd7a",
   "metadata": {},
   "source": [
    "#### VGG16+Channel Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e21b4-d83f-48cf-9d50-3caf795eb40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义CA模块\n",
    "def CA_module(x):\n",
    "    avgpool = GlobalAveragePooling2D(name='channel_avgpool')(x)\n",
    "    maxpool = GlobalMaxPool2D(name='channel_maxpool')(x)\n",
    "    # Shared MLP\n",
    "    Dense_layer1 = Dense(128//8,activation='relu', name='channel_fc1')\n",
    "    Dense_layer2 = Dense(128, activation='relu', name='channel_fc2')\n",
    "    avg_out = Dense_layer2(Dense_layer1(avgpool))\n",
    "    max_out = Dense_layer2(Dense_layer1(maxpool))\n",
    "\n",
    "    #Channel Attention\n",
    "    channel = layers.add([avg_out, max_out])\n",
    "    channel = Activation('sigmoid', name='channel_sigmoid')(channel)\n",
    "    channel = Reshape((1, 1, 128), name='channel_reshape')(channel)\n",
    "    channel = Conv2D(128, (1, 1), strides=(1, 1), padding='same', name='adjust_channel_dim')(channel)\n",
    "    #channel = Reshape((15,15,256), name='channel_reshape')(channel)\n",
    "    channel_out = tf.multiply(x, channel)\n",
    "\n",
    "    x=channel_out\n",
    "    return x\n",
    "# 实例化一个具有预训练权重的基础模型\n",
    "base_model = VGG16(weights=\"imagenet\", input_shape=(60,60,3), include_top=False)\n",
    "# 冻结该基础模型，参数不可变\n",
    "base_model.trainable = False\n",
    "# 根据基础模型创建一个新模型\n",
    "inputs = keras.Input(shape=(60, 60, 3))# 输入\n",
    "x = base_model(inputs, training=False)\n",
    "# 获取VGG16模型的前2个blocks\n",
    "blocks_1_2 = base_model.layers[1:6]\n",
    "blocks_3_5=base_model.layers[7:19]\n",
    "# 创建新的VGG16模型，并在第2个block后插入CBAM模块\n",
    "x = inputs\n",
    "for layer in blocks_1_2:\n",
    "    x = layer(x)\n",
    "    if layer.name == 'block2_conv2':\n",
    "        x = CA_module(x)\n",
    "# 第3-5个block仍为原迁移学习模型\n",
    "for layer in blocks_3_5:\n",
    "    x = layer(x)\n",
    "# 增加新层\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "#创建一个Dropout层\n",
    "x=layers.Dropout(0.5)(x)\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "outputs = keras.layers.Dense(1,kernel_regularizer=l2(0.01),activity_regularizer=l1(0.02))(x)\n",
    "print(outputs.shape)\n",
    "# 创建新模型\n",
    "model_CA = keras.Model(inputs, outputs)\n",
    "model_CA.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca41eb6e-ed7b-443c-9622-66c18c4a7093",
   "metadata": {},
   "source": [
    "####  VGG16+Spatial Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d15ac0b-dd4d-4545-ae89-a6f6ffc63cc0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 60, 60, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 60, 60, 64)   1792        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 60, 60, 64)   36928       block1_conv1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 30, 30, 64)   0           block1_conv2[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 30, 30, 128)  73856       block1_pool[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 30, 30, 128)  147584      block2_conv1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 15, 15, 128)  0           block2_conv2[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 15, 15, 256)  295168      block2_pool[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 15, 15, 256)  590080      block3_conv1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 15, 15, 256)  590080      block3_conv2[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 7, 7, 256)    0           block3_conv3[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 7, 7, 512)    1180160     block3_pool[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 7, 7, 512)    2359808     block4_conv1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 7, 7, 512)    2359808     block4_conv2[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_spatial_avgpool (Te [(None, 7, 7, 1)]    0           block4_conv3[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_spatial_maxpool (Te [(None, 7, 7, 1)]    0           block4_conv3[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 7, 7, 2)      0           tf_op_layer_spatial_avgpool[0][0]\n",
      "                                                                 tf_op_layer_spatial_maxpool[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "spatial_conv2d (Conv2D)         (None, 7, 7, 1)      99          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_sigmoid (Activation)    (None, 7, 7, 1)      0           spatial_conv2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 7, 7, 1)      4           spatial_sigmoid[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_conv2d_dim (Conv2D)     (None, 7, 7, 512)    1024        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           multiple             2359808     spatial_conv2d_dim[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           multiple             2359808     block5_conv1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           multiple             2359808     block5_conv2[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      multiple             0           block5_conv3[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           block5_pool[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            513         global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 14,716,328\n",
      "Trainable params: 1,638\n",
      "Non-trainable params: 14,714,690\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 定义SA模块\n",
    "def SA_module(x): \n",
    "# Spatial Attention\n",
    "    avgpool = tf.reduce_mean(x, axis=3, keepdims=True, name='spatial_avgpool')\n",
    "    maxpool = tf.reduce_max(x, axis=3, keepdims=True, name='spatial_maxpool')\n",
    "    spatial = Concatenate(axis=3)([avgpool, maxpool])\n",
    "\n",
    "    spatial = Conv2D(1, (7,7), strides=1, padding='same',name='spatial_conv2d')(spatial)\n",
    "    spatial_out = Activation('sigmoid', name='spatial_sigmoid')(spatial)\n",
    "    spatial_out = BatchNormalization()(spatial_out)\n",
    "    spatial_out = Conv2D(256, (1, 1), strides=1, padding='same', name='spatial_conv2d_dim')(spatial_out)\n",
    "    \n",
    "    x=spatial_out\n",
    "    return x\n",
    "# 实例化一个具有预训练权重的基础模型\n",
    "base_model = VGG16(weights=\"imagenet\", input_shape=(60,60,3), include_top=False)\n",
    "# 冻结该基础模型，参数不可变\n",
    "base_model.trainable = False\n",
    "# 根据基础模型创建一个新模型\n",
    "inputs = keras.Input(shape=(60, 60, 3))# 输入\n",
    "x = base_model(inputs, training=False)\n",
    "# 获取VGG16模型的前2个blocks\n",
    "blocks_1_2 = base_model.layers[1:6]\n",
    "blocks_3_5=base_model.layers[7:19]\n",
    "# 创建新的VGG16模型，并在第2个block后插入CBAM模块\n",
    "x = inputs\n",
    "for layer in blocks_1_2:\n",
    "    x = layer(x)\n",
    "    if layer.name == 'block2_conv2':\n",
    "        x = SA_module(x)\n",
    "# 第3-5个block仍为原迁移学习模型\n",
    "for layer in blocks_3_5:\n",
    "    x = layer(x)\n",
    "# 增加新层\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "#创建一个Dropout层\n",
    "x=layers.Dropout(0.5)(x)\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "outputs = keras.layers.Dense(1,kernel_regularizer=l2(0.01),activity_regularizer=l1(0.02))(x)\n",
    "print(outputs.shape)\n",
    "# 创建新模型\n",
    "model_SA = keras.Model(inputs, outputs)\n",
    "model_SA.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb02c9a-2fd9-451c-9334-415a4e6dae82",
   "metadata": {},
   "source": [
    "#### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "964397fe-f7e9-4f11-b428-f8ca579de044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 60, 60, 3)]       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, 1, 1, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 14,715,201\n",
      "Trainable params: 513\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##VGG16\n",
    "# 实例化一个具有预训练权重的基础模型\n",
    "base_model = VGG16(weights=\"imagenet\", input_shape=(60,60,3), include_top=False)\n",
    "# 冻结该基础模型，参数不可变\n",
    "base_model.trainable = False\n",
    "# 根据基础模型创建一个新模型\n",
    "# 输入\n",
    "inputs = keras.Input(shape=(60, 60, 3))\n",
    "# We make sure that the base_model is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning, as you will\n",
    "# learn in a few paragraphs.\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "# 增加新层\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "print(outputs.shape)\n",
    "# 创建新模型\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbbb811-1083-476a-bd02-dabe0ff285e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
